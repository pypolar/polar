{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"POint cloud LAtent Registration","text":""},{"location":"#getting-started","title":"Getting started","text":"<p>POLAR is a method to simultaneously register numerous highly degraded point clouds corresponding to views of the same unknown reference object.</p>"},{"location":"#installation","title":"Installation","text":"<p>Warning</p> <p>PyTorch3D is required by POLAR. Since its installation is quite specific, you need to install it manually.</p> <p>If you want to user POLAR with the provided pretrained autoencoder, run <pre><code>pip install polaregistration\n</code></pre></p> <p>If you want to retrain the autoencoder on your own, run <pre><code>pip install polaregistration[train]\n</code></pre></p> <p>If you want to use the interactive visualization function, run <pre><code>pip install polaregistration[vis]\n</code></pre></p> <p>Finally, to install everything, run <pre><code>pip install polaregistration[all]\n</code></pre></p>"},{"location":"#minimal-example","title":"Minimal example","text":"<p><pre><code>from polar import load_sample_data, POLAR\n\nX, degradations, R_abs_gt = load_sample_data()\n\nmodel = POLAR(**degradations)\nX_hat = model.fit_transform(X)\n</code></pre> POLAR partially respects the Scikit-Learn Estimator API. Specifically, it has the two main methods:</p> <ul> <li><code>fit(X: Tensor | Sequence[Tensor]) -&gt; None</code> </li> <li><code>fit_transform(X: Tensor | Sequence[Tensor]) -&gt; Tensor | Sequence[Tensor]</code></li> </ul> <p>They take a list of PyTorch tensors (each of shape \\((K_i, 3)\\) if point clouds are of varying lengths) or a single batch tensor of shape \\((N, K, 3)\\) containing all the (same length) views.</p>"},{"location":"api/train/","title":"PointNet AutoEncoder training on ModelNet40","text":"<p>Training script can be found in <code>src.polar.train.train.py</code> with the function <code>main</code>. It can be imported from <code>polar</code> as <code>train_ae</code>.</p>"},{"location":"api/train/#minimal-example","title":"Minimal example","text":"<p>Typically, a training would be done as follows:</p> <ol> <li>Create a file <code>train_ae.py</code> with the following: <pre><code>from polar import train_ae\n\nif __name__ == '__main__':\n    train_ae()\n</code></pre></li> <li>Then, run</li> </ol> <pre><code>python train_ae.py --name demo --shuffle --sigma 0.05\n</code></pre>"},{"location":"api/train/#parameters","title":"Parameters","text":"<p>It accepts the following parameters:</p> <ul> <li> <p>Base</p> <ul> <li><code>name</code> (Required)</li> <li><code>log_dir</code> (<code>str</code>, default=<code>'logs/ae'</code>)</li> <li><code>batch_size</code> (<code>int</code>, default=<code>64</code>)</li> <li><code>num_workers</code> (<code>int</code>, default=<code>4</code>)</li> </ul> </li> <li> <p>Dataset </p> <ul> <li><code>rootdir</code> (<code>str</code>, default=<code>'modelnet'</code>)</li> <li><code>classes</code> (<code>str</code>, default=<code>None</code>)</li> <li><code>exclude_classes</code> (<code>str</code>, default=<code>None</code>)</li> <li><code>samples_per_class</code> (<code>int</code>, default=<code>None</code>)</li> </ul> </li> <li> <p>Preprocessing</p> <ul> <li><code>shuffle</code> (<code>bool</code>, default=<code>False</code>)</li> <li><code>num_points</code> (<code>int</code>, default=<code>1024</code>)</li> <li><code>max_angle</code> (<code>int</code>, default=<code>180</code>)</li> <li><code>max_trans</code> (<code>float</code>, default=<code>0.0</code>)</li> </ul> </li> <li> <p>Augmentations</p> <ul> <li><code>sigma</code> (<code>float</code>, default=<code>0.0</code>)</li> <li><code>min_scale</code> (<code>float</code>, default=<code>1.0</code>)</li> <li><code>keep_ratio</code> (<code>float</code>, default=<code>1.0</code>)</li> <li><code>p</code> (<code>float</code>, default=<code>0.5</code>)</li> </ul> </li> <li> <p>Autoencoder</p> <ul> <li><code>first_stage_widths</code> (<code>int</code>, default=<code>(64, 64)</code>)</li> <li><code>second_stage_widths</code> (<code>int</code>, default=<code>(64, 128, 1024)</code>)</li> <li><code>decoder_widths</code> (<code>int</code>, default=<code>(1024, 1024)</code>)</li> <li><code>dropout</code> (<code>float</code>, default=<code>0.1</code>)</li> </ul> </li> <li> <p>Training</p> <ul> <li><code>lr</code> (<code>float</code>, default=<code>0.001</code>)</li> <li><code>resume_optimizer</code> (<code>bool</code>, default=<code>False</code>)</li> <li><code>checkpoint</code> (<code>str</code>, default=<code>None</code>)</li> <li><code>freeze_decoder</code> (<code>bool</code>, default=<code>False</code>)</li> <li><code>epochs</code> (<code>int</code>,  default=<code>150</code>)</li> </ul> </li> <li> <p>Loss</p> <ul> <li><code>norm</code> (<code>int</code>, default=<code>2</code>)</li> <li><code>density_weight</code> (<code>float</code>, default=<code>0.0</code>)</li> <li><code>density_radius</code> (<code>float</code>, default=<code>0.1</code>)</li> </ul> </li> </ul>"},{"location":"api/visualize/","title":"Interactive visualization","text":""},{"location":"api/visualize/#src.polar.example.utils.interactive_plot","title":"<code>interactive_plot(data: np.ndarray | Sequence[np.ndarray] | Tensor | Sequence[Tensor], labels: Optional[str | Sequence[str]] = None, point_size: int = 3, opacity: float = 0.8, color: Optional[np.ndarray] = None, cmap: Optional[str] = None, constraint_x: bool = False, constraint_y: bool = False, constraint_z: bool = False, return_fig: bool = False, width: int = 500, height: int = 500) -&gt; Optional[go.Figure]</code>","text":"<p>Interactive plot of point cloud(s) based on Plotly. Can display N pointcloud(s).</p> <p>Parameters:</p> <ul> <li> <code>data</code>               (<code>ndarray | Sequence[ndarray] | Tensor | Sequence[Tensor]</code>)           \u2013            <p>description</p> </li> <li> <code>labels</code>               (<code>Optional[str | Sequence[str]]</code>, default:                   <code>None</code> )           \u2013            <p>description. Defaults to None.</p> </li> <li> <code>point_size</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>description. Defaults to 3.</p> </li> <li> <code>opacity</code>               (<code>float</code>, default:                   <code>0.8</code> )           \u2013            <p>description. Defaults to 0.8.</p> </li> <li> <code>color</code>               (<code>Optional[ndarray]</code>, default:                   <code>None</code> )           \u2013            <p>description. Defaults to None.</p> </li> <li> <code>cmap</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>description. Defaults to None.</p> </li> <li> <code>constraint_x</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>description. Defaults to False.</p> </li> <li> <code>constraint_y</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>description. Defaults to False.</p> </li> <li> <code>constraint_z</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>description. Defaults to False.</p> </li> <li> <code>return_fig</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>description. Defaults to False.</p> </li> <li> <code>width</code>               (<code>int</code>, default:                   <code>500</code> )           \u2013            <p>description. Defaults to 500.</p> </li> <li> <code>height</code>               (<code>int</code>, default:                   <code>500</code> )           \u2013            <p>description. Defaults to 500.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Optional[Figure]</code>           \u2013            <p>Optional[go.Figure]: description</p> </li> </ul> Source code in <code>src/polar/example/utils.py</code> <pre><code>def interactive_plot(\n    data: np.ndarray | Sequence[np.ndarray] | Tensor | Sequence[Tensor],\n    labels: Optional[str | Sequence[str]] = None,\n    point_size: int = 3,\n    opacity: float = 0.8,\n    color: Optional[np.ndarray] = None,\n    cmap: Optional[str] = None,\n    constraint_x: bool = False,\n    constraint_y: bool = False,\n    constraint_z: bool = False,\n    return_fig: bool = False,\n    width: int = 500,\n    height: int = 500,\n) -&gt; Optional[go.Figure]:\n    \"\"\" Interactive plot of point cloud(s) based on Plotly. Can display N pointcloud(s).\n\n    Args:\n        data (np.ndarray | Sequence[np.ndarray] | Tensor | Sequence[Tensor]): _description_\n        labels (Optional[str  |  Sequence[str]], optional): _description_. Defaults to None.\n        point_size (int, optional): _description_. Defaults to 3.\n        opacity (float, optional): _description_. Defaults to 0.8.\n        color (Optional[np.ndarray], optional): _description_. Defaults to None.\n        cmap (Optional[str], optional): _description_. Defaults to None.\n        constraint_x (bool, optional): _description_. Defaults to False.\n        constraint_y (bool, optional): _description_. Defaults to False.\n        constraint_z (bool, optional): _description_. Defaults to False.\n        return_fig (bool, optional): _description_. Defaults to False.\n        width (int, optional): _description_. Defaults to 500.\n        height (int, optional): _description_. Defaults to 500.\n\n    Raises:\n        ValueError: _description_\n\n    Returns:\n        Optional[go.Figure]: _description_\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        data = [data]\n    if isinstance(data, tuple):\n        data = list(data)\n    for i, x in enumerate(data):\n        if isinstance(x, Tensor) and x.is_cuda:\n            data[i] = x.cpu()\n    N = len(data)\n    if labels is None:\n        labels = [f\"pointcloud {i + 1}\" for i in range(N)]\n    if not isinstance(labels, (list, tuple)):\n        labels = (labels, )\n    if labels is not None and not len(data) == len(labels):\n        raise ValueError(f\"You gave {len(data)} pointclouds but {len(labels)} labels.\")\n    all_cmaps = get_all_named_cmaps()\n    if isinstance(cmap, str):\n        cmaps = N * [cmap]\n    elif not (isinstance(cmap, (tuple, list)) and len(cmap) == len(data)):\n        cmaps = all_cmaps[:N]\n    else:\n        cmaps = cmap\n    traces = list()\n    for pointcloud, label, cmap in zip(data, labels, cmaps):\n        x, y, z = pointcloud[:, 0], pointcloud[:, 1], pointcloud[:, 2]\n        c = color if color is not None else z\n        marker_kwargs = dict(size=point_size, opacity=opacity, color=c, colorscale=cmap)\n        scatter_kwargs = dict(visible=True, mode='markers', name=label, marker=marker_kwargs)\n        traces.append(go.Scatter3d(x=x, y=y, z=z, **scatter_kwargs))\n    layout = dict(\n        width=width, height=height,\n        xaxis=dict(range=[0, 1]), yaxis=dict(range=[0, 1]), margin=dict(t=50)\n    )\n    if constraint_x:\n        layout['scene'] = dict(xaxis=dict(nticks=4, range=[-1, 1]))\n    if constraint_y:\n        layout['scene'] = dict(yaxis=dict(nticks=4, range=[-1, 1]))\n    if constraint_z:\n        layout['scene'] = dict(zaxis=dict(nticks=4, range=[-1, 1]))\n    fig = go.Figure(data=traces)\n    fig.update_layout(**layout)\n    if return_fig:\n        return fig\n    fig.show()\n</code></pre>"},{"location":"api/data/core/","title":"Core","text":""},{"location":"api/data/core/#src.polar.train.data.transforms.core.Transform","title":"<code>Transform(p: float = 1.0)</code>","text":"<p>Base Transform class. Every Transforms inherits this class and implements <code>get_params()</code> and <code>apply()</code>; <code>apply()</code> is always based on the functional counterpart of the Transform class. Any Transform accepts multiple batches of point clouds (typically sources and targets) as it is often desired to apply the same random transform to many batches of points clouds. If multiple point clouds are passed, they MUST all have the same length. Any Transform is applied with a provided probability <code>self.p</code>.</p> Source code in <code>src/polar/train/data/transforms/core.py</code> <pre><code>def __init__(self, p: float = 1.0) -&gt; None:\n    self.p = p\n</code></pre>"},{"location":"api/data/core/#src.polar.train.data.transforms.core.Transform.get_batch_size","title":"<code>get_batch_size(**data: Tensor) -&gt; int</code>  <code>staticmethod</code>","text":"<p>Static method. Assume every values in data dict is of same shape.</p> Source code in <code>src/polar/train/data/transforms/core.py</code> <pre><code>@staticmethod\ndef get_batch_size(**data: Tensor) -&gt; int:\n    \"\"\" Static method. Assume every values in data dict is of same shape. \"\"\"\n    return list(data.values())[0].shape[0]\n</code></pre>"},{"location":"api/data/core/#src.polar.train.data.transforms.core.Transform.get_num_points","title":"<code>get_num_points(**data: Tensor) -&gt; int</code>  <code>staticmethod</code>","text":"<p>Static method. Assume every values in data dict is of same shape.</p> Source code in <code>src/polar/train/data/transforms/core.py</code> <pre><code>@staticmethod\ndef get_num_points(**data: Tensor) -&gt; int:\n    \"\"\" Static method. Assume every values in data dict is of same shape. \"\"\"\n    return list(data.values())[0].shape[1]\n</code></pre>"},{"location":"api/data/core/#src.polar.train.data.transforms.core.Transform.get_params","title":"<code>get_params(**data: Tensor) -&gt; dict</code>","text":"<p>Shared parameters for one apply (usually random values).</p> <p>Parameters:</p> <ul> <li> <code>**data</code>               (<code>Tensor</code>, default:                   <code>{}</code> )           \u2013            <p>Dictionary with str as keys and batch of point clouds of shape              <code>(batch_size, num_points, *)</code> where <code>*</code> denotes spatial coordinates as              values. Typically, <code>data = {'source': ..., 'target': ...}</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>params</code> (              <code>dict</code> )          \u2013            <p>Params used by the transform (e.g. Euler angles for rotation).</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/core.py</code> <pre><code>def get_params(self, **data: Tensor) -&gt; dict:\n    \"\"\" Shared parameters for one apply (usually random values).\n\n    Args:\n        **data (Tensor): Dictionary with str as keys and batch of point clouds of shape\n                         `(batch_size, num_points, *)` where `*` denotes spatial coordinates as\n                         values. Typically, `data = {'source': ..., 'target': ...}`.\n\n    Returns:\n        params (dict): Params used by the transform (e.g. Euler angles for rotation).\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/data/core/#src.polar.train.data.transforms.core.Transform.apply","title":"<code>apply(pointclouds: Tensor, **params) -&gt; Tensor</code>","text":"<p>Apply the functional transform with the params obtained by <code>self.get_params()</code> to     one batch of point clouds.</p> <p>Parameters:</p> <ul> <li> <code>pointclouds</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds of shape <code>(batch_size, num_points, *)</code>                   where <code>*</code> denotes spatial coordinates.</p> </li> </ul> <p>Returns:     Transformed tensor: Transformed batch of point clouds of shape <code>(batch_size,                         num_points, *)</code> where <code>*</code> denotes spatial coordinates.</p> Source code in <code>src/polar/train/data/transforms/core.py</code> <pre><code>def apply(self, pointclouds: Tensor, **params) -&gt; Tensor:\n    \"\"\" Apply the functional transform with the params obtained by `self.get_params()` to\n        one batch of point clouds.\n\n    Args:\n        pointclouds (Tensor): Batch of point clouds of shape `(batch_size, num_points, *)`\n                              where `*` denotes spatial coordinates.\n    Returns:\n        Transformed tensor: Transformed batch of point clouds of shape `(batch_size,\n                            num_points, *)` where `*` denotes spatial coordinates.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/data/core/#src.polar.train.data.transforms.core.Transform.__call__","title":"<code>__call__(**data: Tensor) -&gt; dict[str, Tensor]</code>","text":"<p>Call <code>self.apply</code> with a probability <code>self.p</code> on every values in the provided     dictionary.</p> <p>Returns:</p> <ul> <li> <code>dict[str, Tensor]</code>           \u2013            <p>Transformed data: Same dictionary structure as input. The values have been               transformed (with a certain probability).</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/core.py</code> <pre><code>def __call__(self, **data: Tensor) -&gt; dict[str, Tensor]:\n    \"\"\" Call `self.apply` with a probability `self.p` on every values in the provided\n        dictionary.\n\n    Returns:\n        Transformed data: Same dictionary structure as input. The values have been\n                          transformed (with a certain probability).\n    \"\"\"\n    if torch.rand(size=(1, )) &lt; self.p:\n        params = self.get_params(**data)\n        self.register_params(params)\n        for k, v in data.items():\n            data[k] = self.apply(v, **params)\n    return data\n</code></pre>"},{"location":"api/data/core/#src.polar.train.data.transforms.core.Compose","title":"<code>Compose(transforms: Sequence[Transform], p: float = 1.0)</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Very simple mechanism to chain Transforms. Nothing more than a wrapper able to store a sequence of Transforms, to be applied iteratively on every values in a provided dictionary. It also has a probability, typically used so that only a portion of a dataset is augmented during training.</p> <p>Example</p> <pre><code>from polar.train.data import transforms as T\ncenter_normalize = T.Compose((T.Center(), T.Normalize()))\n</code></pre> <p>Parameters:</p> <ul> <li> <code>transforms</code>               (<code>Sequence[Transform]</code>)           \u2013            <p>Transformations to be randomly composed during a                               call.</p> </li> <li> <code>p</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Probability to apply the provided sequence. Defaults to 1.0.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/core.py</code> <pre><code>def __init__(self, transforms: Sequence[Transform], p: float = 1.0) -&gt; None:\n    \"\"\"_summary_\n\n    Args:\n        transforms (Sequence[Transform]): Transformations to be randomly composed during a\n                                          call.\n        p (float, optional): Probability to apply the provided sequence. Defaults to 1.0.\n    \"\"\"\n    super(Compose, self).__init__()\n    self.transforms = {t.__class__.__name__: t for t in transforms}\n    self.p = p\n</code></pre>"},{"location":"api/data/dataloaders/","title":"ModelNet40 Data Loaders","text":"<p>Some utility factories are provided to easily instanciate dataloaders.</p>"},{"location":"api/data/dataloaders/#core-modelnet40-utilities","title":"Core ModelNet40 utilities","text":""},{"location":"api/data/dataloaders/#src.polar.train.data.modelnet.download_modelnet40","title":"<code>download_modelnet40(dir: Path | str | None = None) -&gt; None</code>","text":"<p>Download the full ModelNet40 dataset archive as two <code>.h5</code> files (train &amp; test) (~ 1 Go).</p> <p>Parameters:</p> <ul> <li> <code>dir</code>               (<code>Path | str | None</code>, default:                   <code>None</code> )           \u2013            <p>Where to store the downloaded filed. Defaults to None.</p> </li> </ul> Source code in <code>src/polar/train/data/modelnet.py</code> <pre><code>def download_modelnet40(dir: Path | str | None = None) -&gt; None:\n    \"\"\" Download the full ModelNet40 dataset archive as two `.h5` files (train &amp; test) (~ 1 Go).\n\n    Args:\n        dir (Path | str | None, optional): Where to store the downloaded filed. Defaults to None.\n    \"\"\"\n    if dir is None:\n        dir = Path(__file__).resolve().parent / 'modelnet40'\n    dir = Path(dir).resolve()\n    dir.mkdir(exist_ok=True)\n    if not (dir / 'modelnet40_ply_hdf5_2048').exists():\n        www = Path('https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip')\n        os.system(f'wget --no-check-certificate {www}; unzip {www.name}')\n        os.system(f'mv {www.stem} {str(dir)}')\n        os.system(f'rm {www.name}')\n</code></pre>"},{"location":"api/data/dataloaders/#src.polar.train.data.modelnet.ModelNet","title":"<code>ModelNet(rootdir: str = 'modelnet', split: str = 'train', classes: Sequence[str] | None = None, exclude_classes: Sequence[str] | None = None, samples_per_class: int | None = None, return_labels: bool = False)</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>Parameters:</p> <ul> <li> <code>rootdir</code>               (<code>str</code>, default:                   <code>'modelnet'</code> )           \u2013            <p>Path to the directory containing the <code>.h5</code> files. Defaults to 'modelnet'.</p> </li> <li> <code>split</code>               (<code>str</code>, default:                   <code>'train'</code> )           \u2013            <p>'train' or 'test. Defaults to 'train'.</p> </li> <li> <code>classes</code>               (<code>Sequence[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Shape categories to use. If <code>None</code>, load all categories. See <code>ModelNet.all_classes</code>. Defaults to <code>None</code>.</p> </li> <li> <code>exclude_classes</code>               (<code>Sequence[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Shape categories to exclude from the dataset. Defaults to <code>None</code>.</p> </li> <li> <code>samples_per_class</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Number of point clouds per category to load. Defaults to <code>None</code>.</p> </li> <li> <code>return_labels</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, return the class index alongside the point cloud. Defaults to <code>False</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/modelnet.py</code> <pre><code>def __init__(\n    self,\n    rootdir: str = 'modelnet', split: str = 'train', classes: Sequence[str] | None = None,\n    exclude_classes: Sequence[str] | None = None, samples_per_class: int | None = None, return_labels: bool = False\n) -&gt; None:\n    \"\"\"_summary_\n\n    Args:\n        rootdir (str, optional): Path to the directory containing the `.h5` files. Defaults to 'modelnet'.\n        split (str, optional): 'train' or 'test. Defaults to 'train'.\n        classes (Sequence[str] | None, optional):\n            Shape categories to use. If `None`, load all categories. See `ModelNet.all_classes`. Defaults to `None`.\n        exclude_classes (Sequence[str] | None, optional):\n            Shape categories to exclude from the dataset. Defaults to `None`.\n        samples_per_class (int | None, optional): Number of point clouds per category to load. Defaults to `None`.\n        return_labels (bool, optional):\n            If `True`, return the class index alongside the point cloud. Defaults to `False`.\n    \"\"\"\n    super().__init__()\n    load_params = (rootdir, split, classes, exclude_classes, samples_per_class)\n    self.points, self.labels = load_and_select_samples(*load_params)\n    self.split = split\n    self.return_labels = return_labels\n</code></pre>"},{"location":"api/data/dataloaders/#src.polar.train.data.modelnet.ModelNet.all_classes","title":"<code>all_classes: tuple[str, ...]</code>  <code>property</code>","text":"<p>Tuple of 40 strings, one for each class.</p>"},{"location":"api/data/dataloaders/#base-loaders","title":"Base Loaders","text":""},{"location":"api/data/dataloaders/#src.polar.train.data.factory.get_modelnet_dataloader","title":"<code>get_modelnet_dataloader(batch_size: int, num_workers: int, rootdir: str = 'modelnet', split: str = 'train', classes: Sequence[str] | None = None, exclude_classes: Sequence[str] | None = None, samples_per_class: int | None = None, return_labels: bool = False) -&gt; DataLoader[ModelNet]</code>","text":"<p>Instanciate a basic ModelNet Pytorch dataloader. Each batch is composed of fixed length point clouds     <code>(batch_size, num_points, 3)</code>.</p> <p>Parameters:</p> <ul> <li> <code>batch_size</code>               (<code>int</code>)           \u2013            <p>Batch size.</p> </li> <li> <code>num_workers</code>               (<code>int</code>)           \u2013            <p>Parallel loading with <code>num_workers</code> processes.</p> </li> <li> <code>rootdir</code>               (<code>str</code>, default:                   <code>'modelnet'</code> )           \u2013            <p>Path to the directory containing the <code>.h5</code> files. Defaults to 'modelnet'.</p> </li> <li> <code>split</code>               (<code>str</code>, default:                   <code>'train'</code> )           \u2013            <p>'train' or 'test. Defaults to 'train'.</p> </li> <li> <code>classes</code>               (<code>Sequence[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Shape categories to use. If <code>None</code>, load all categories. See <code>ModelNet.all_classes</code>. Defaults to <code>None</code>.</p> </li> <li> <code>exclude_classes</code>               (<code>Sequence[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Shape categories to exclude from the dataset. Defaults to <code>None</code>.</p> </li> <li> <code>samples_per_class</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Number of point clouds per category to load. Defaults to <code>None</code>.</p> </li> <li> <code>return_labels</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, return the class index alongside the point cloud. Defaults to <code>False</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataLoader[ModelNet]</code>           \u2013            <p>Standard Pytorch DataLoader.</p> </li> </ul> Source code in <code>src/polar/train/data/factory.py</code> <pre><code>def get_modelnet_dataloader(\n    batch_size: int, num_workers: int,\n    rootdir: str = 'modelnet', split: str = 'train', classes: Sequence[str] | None = None,\n    exclude_classes: Sequence[str] | None = None, samples_per_class: int | None = None, return_labels: bool = False\n) -&gt; DataLoader[ModelNet]:\n    \"\"\" Instanciate a basic ModelNet Pytorch dataloader. Each batch is composed of fixed length point clouds\n        `(batch_size, num_points, 3)`.\n\n    Args:\n        batch_size (int): Batch size.\n        num_workers (int): Parallel loading with `num_workers` processes.\n        rootdir (str, optional): Path to the directory containing the `.h5` files. Defaults to 'modelnet'.\n        split (str, optional): 'train' or 'test. Defaults to 'train'.\n        classes (Sequence[str] | None, optional):\n            Shape categories to use. If `None`, load all categories. See `ModelNet.all_classes`. Defaults to `None`.\n        exclude_classes (Sequence[str] | None, optional):\n            Shape categories to exclude from the dataset. Defaults to `None`.\n        samples_per_class (int | None, optional): Number of point clouds per category to load. Defaults to `None`.\n        return_labels (bool, optional):\n            If `True`, return the class index alongside the point cloud. Defaults to `False`.\n\n    Returns:\n        Standard Pytorch DataLoader.\n    \"\"\"\n    dataset = ModelNet(rootdir, split, classes, exclude_classes, samples_per_class, return_labels)\n    loader_params = dict(num_workers=num_workers, pin_memory=True, shuffle=True, drop_last=False)\n    return DataLoader(dataset, **loader_params, batch_size=batch_size)  # type: ignore\n</code></pre>"},{"location":"api/data/dataloaders/#src.polar.train.data.factory.get_modelnet_dataloaders","title":"<code>get_modelnet_dataloaders(batch_size: int, num_workers: int, rootdir: str = 'modelnet', classes: Sequence[str] | None = None, exclude_classes: Sequence[str] | None = None, samples_per_class: int | None = None, return_labels: bool = False) -&gt; tuple[DataLoader[ModelNet], DataLoader[ModelNet]]</code>","text":"<p>Same as src.polar.train.data.factory.get_modelnet_dataloader, but returns a tuple of train and test     dataloaders.</p> <p>Returns:</p> <ul> <li> <code>tuple[DataLoader[ModelNet], DataLoader[ModelNet]]</code>           \u2013            <p>Train loader, Test loader.</p> </li> </ul> Source code in <code>src/polar/train/data/factory.py</code> <pre><code>def get_modelnet_dataloaders(\n    batch_size: int, num_workers: int,\n    rootdir: str = 'modelnet', classes: Sequence[str] | None = None,\n    exclude_classes: Sequence[str] | None = None, samples_per_class: int | None = None, return_labels: bool = False\n) -&gt; tuple[DataLoader[ModelNet], DataLoader[ModelNet]]:\n    \"\"\" Same as [src.polar.train.data.factory.get_modelnet_dataloader][], but returns a tuple of train and test\n        dataloaders.\n\n    Returns:\n        Train loader, Test loader.\n    \"\"\"\n    split = 'train'\n    train_loader = get_modelnet_dataloader(**locals())\n    split = 'test'\n    locals_ = {k: v for k, v in locals().items() if k != 'train_loader'}\n    test_loader = get_modelnet_dataloader(**locals_)\n    return train_loader, test_loader\n</code></pre>"},{"location":"api/data/dataloaders/#src.polar.train.data.factory.get_modelnet_dataloader_from_args","title":"<code>get_modelnet_dataloader_from_args(args: Namespace) -&gt; DataLoader[ModelNet]</code>","text":"<p>Same as src.polar.train.data.factory.get_modelnet_dataloader, but accepts an <code>argparse.Namespace</code> object     instead of keyword arguments.</p> <p>Returns:</p> <ul> <li> <code>DataLoader[ModelNet]</code>           \u2013            <p>Standard Pytorch DataLoader.</p> </li> </ul> Source code in <code>src/polar/train/data/factory.py</code> <pre><code>def get_modelnet_dataloader_from_args(args: Namespace) -&gt; DataLoader[ModelNet]:\n    \"\"\" Same as [src.polar.train.data.factory.get_modelnet_dataloader][], but accepts an `argparse.Namespace` object\n        instead of keyword arguments.\n\n    Returns:\n        Standard Pytorch DataLoader.\n    \"\"\"\n    dataset = ModelNet.from_args(args)\n    loader_params = dict(num_workers=args.num_workers, pin_memory=True, shuffle=True, drop_last=False)\n    return DataLoader(dataset, **loader_params, batch_size=args.batch_size)\n</code></pre>"},{"location":"api/data/dataloaders/#src.polar.train.data.factory.get_modelnet_dataloaders_from_args","title":"<code>get_modelnet_dataloaders_from_args(args: Namespace) -&gt; tuple[DataLoader[ModelNet], DataLoader[ModelNet]]</code>","text":"<p>Same as src.polar.train.data.factory.get_modelnet_dataloader_from_args, but returns a tuple of train and test     dataloaders.</p> <p>Returns:</p> <ul> <li> <code>tuple[DataLoader[ModelNet], DataLoader[ModelNet]]</code>           \u2013            <p>Train loader, Test loader.</p> </li> </ul> Source code in <code>src/polar/train/data/factory.py</code> <pre><code>def get_modelnet_dataloaders_from_args(args: Namespace) -&gt; tuple[DataLoader[ModelNet], DataLoader[ModelNet]]:\n    \"\"\" Same as [src.polar.train.data.factory.get_modelnet_dataloader_from_args][], but returns a tuple of train and test\n        dataloaders.\n\n    Returns:\n        Train loader, Test loader.\n    \"\"\"\n    args.split = 'train'\n    train_loader = get_modelnet_dataloader_from_args(args)\n    args.split = 'test'\n    test_loader = get_modelnet_dataloader_from_args(args)\n    return train_loader, test_loader\n</code></pre>"},{"location":"api/data/dataloaders/#augmented-loaders","title":"Augmented Loaders","text":""},{"location":"api/data/dataloaders/#src.polar.train.data.augmented_loader.AugmentedDataLoader","title":"<code>AugmentedDataLoader(dataloader: DataLoader[ModelNet], num_points: int = 1024, shuffle: bool = False, sigma: float = 0.0, min_scale: float = 1.0, max_angle: float = 180.0, max_trans: float = 0.0, keep_ratio: float = 1.0, p: float = 1, handle_device: bool = True)</code>","text":"<p>Apply same motion to sources and targets. Degrade sources only. Intented to be used to train an autoencoder to reconstruct and restore point clouds.</p> <p>Parameters:</p> <ul> <li> <code>dataloader</code>               (<code>DataLoader[ModelNet]</code>)           \u2013            <p>A ModelNet dataloader instance, typically from src.polar.train.data.factory.get_modelnet_dataloader.</p> </li> <li> <code>num_points</code>               (<code>int</code>, default:                   <code>1024</code> )           \u2013            <p>Number of points in each cloud. Defaults to 1024.</p> </li> <li> <code>shuffle</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Shuffle the dense point clouds (5000 points before sampling <code>num_points</code>) points. If <code>True</code>, sources and targets will be two unique sampling of the same underlying surface. Defaults to False.</p> </li> <li> <code>sigma</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Isotropic noise standard deviation. Defaults to <code>0</code>.</p> </li> <li> <code>min_scale</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>If \\(&lt; 1\\), will randomly scale each batch with a factor \\(s \\sim \\mathcal{U}(\\text{min_scale}, 1)\\). Defaults to <code>1</code>.</p> </li> <li> <code>max_angle</code>               (<code>float</code>, default:                   <code>180.0</code> )           \u2013            <p>For each point cloud, randomly sample a rotation whose relative angle with the identity is in \\([0, \\text{max_angle}]\\). Defaults to <code>180</code>.</p> </li> <li> <code>max_trans</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>For each point cloud, randomly sample a translation whose norm is int \\([0, \\text{max_trans}]\\). Defaults to <code>0</code>.</p> </li> <li> <code>keep_ratio</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>If \\(&lt; 1\\), will randomly crop each batch with a factor \\(k \\sim \\mathcal{U}(\\text{keep_ratio}, 1)\\). Defaults to <code>1</code>.</p> </li> <li> <code>p</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Probability to apply the augmentation. Defaults to <code>1</code>.</p> </li> <li> <code>handle_device</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, will guess the device and move point clouds to it. Defaults to <code>True</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/augmented_loader.py</code> <pre><code>def __init__(\n    self, dataloader: DataLoader[ModelNet], num_points: int = 1024, shuffle: bool = False,\n    sigma: float = 0., min_scale: float = 1., max_angle: float = 180., max_trans: float = 0.,\n    keep_ratio: float = 1., p: float = 1, handle_device: bool = True\n) -&gt; None:\n    r\"\"\"_summary_\n\n    Args:\n        dataloader (DataLoader[ModelNet]):\n            A ModelNet dataloader instance, typically from [src.polar.train.data.factory.get_modelnet_dataloader][].\n        num_points (int, optional): Number of points in each cloud. Defaults to 1024.\n        shuffle (bool, optional):\n            Shuffle the dense point clouds (5000 points before sampling `num_points`) points. If `True`, sources\n            and targets will be two unique sampling of the same underlying surface. Defaults to False.\n        sigma (float, optional): Isotropic noise standard deviation. Defaults to `0`.\n        min_scale (float, optional):\n            If $&lt; 1$, will randomly scale each batch with a factor $s \\sim \\mathcal{U}(\\text{min_scale}, 1)$.\n            Defaults to `1`.\n        max_angle (float, optional):\n            For each point cloud, randomly sample a rotation whose relative angle with the identity is in\n            $[0, \\text{max_angle}]$. Defaults to `180`.\n        max_trans (float, optional):\n            For each point cloud, randomly sample a translation whose norm is int $[0, \\text{max_trans}]$.\n            Defaults to `0`.\n        keep_ratio (float, optional):\n            If $&lt; 1$, will randomly crop each batch with a factor $k \\sim \\mathcal{U}(\\text{keep_ratio}, 1)$.\n            Defaults to `1`.\n        p (float, optional): Probability to apply the augmentation. Defaults to `1`.\n        handle_device (bool, optional):\n            If `True`, will guess the device and move point clouds to it. Defaults to `True`.\n    \"\"\"\n    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    self.handle_device = handle_device\n    self.dataloader = dataloader\n    self.num_points = num_points\n    self.shuffle = shuffle\n    self.sigma = sigma\n    self.min_scale = min_scale\n    self.max_angle = max_angle\n    self.max_trans = max_trans\n    self.keep_ratio = keep_ratio\n    self.init_transforms(p)\n</code></pre>"},{"location":"api/data/dataloaders/#src.polar.train.data.factory.get_augmented_dataloader","title":"<code>get_augmented_dataloader(batch_size: int, num_workers: int, rootdir: str = 'modelnet', split: str = 'train', classes: Sequence[str] | None = None, exclude_classes: Sequence[str] | None = None, samples_per_class: int | None = None, return_labels: bool = False, num_points: int = 1024, shuffle: bool = False, sigma: float = 0.0, min_scale: float = 1.0, max_angle: float = 180.0, max_trans: float = 0.0, keep_ratio: float = 1.0, p: float = 1, handle_device: bool = True) -&gt; AugmentedDataLoader</code>","text":"<p>See src.polar.train.data.factory.AugmentedDataLoader for the arguments description.</p> <p>Returns:</p> <ul> <li> <code>AugmentedDataLoader</code>           \u2013            <p>A ModelNet40 dataloader with random motions and degradations.</p> </li> </ul> Source code in <code>src/polar/train/data/factory.py</code> <pre><code>def get_augmented_dataloader(\n    batch_size: int, num_workers: int,\n    rootdir: str = 'modelnet', split: str = 'train', classes: Sequence[str] | None = None,\n    exclude_classes: Sequence[str] | None = None, samples_per_class: int | None = None, return_labels: bool = False,\n    num_points: int = 1024, shuffle: bool = False, sigma: float = 0., min_scale: float = 1.,\n    max_angle: float = 180., max_trans: float = 0., keep_ratio: float = 1., p: float = 1, handle_device: bool = True\n) -&gt; AugmentedDataLoader:\n    \"\"\" See src.polar.train.data.factory.AugmentedDataLoader for the arguments description.\n\n    Returns:\n        A ModelNet40 dataloader with random motions and degradations. \n    \"\"\"\n    dataloader = get_modelnet_dataloader(batch_size, num_workers, rootdir, split, classes, exclude_classes,\n                                         samples_per_class, return_labels)\n    augmented_dataloader = AugmentedDataLoader(dataloader, num_points, shuffle, sigma, min_scale, max_angle, max_trans,\n                                               keep_ratio, p, handle_device)\n    return augmented_dataloader\n</code></pre>"},{"location":"api/data/dataloaders/#src.polar.train.data.factory.get_augmented_dataloaders","title":"<code>get_augmented_dataloaders(batch_size: int, num_workers: int, rootdir: str = 'modelnet', classes: Sequence[str] | None = None, exclude_classes: Sequence[str] | None = None, samples_per_class: int | None = None, return_labels: bool = False, num_points: int = 1024, shuffle: bool = False, sigma: float = 0.0, min_scale: float = 1.0, max_angle: float = 180.0, max_trans: float = 0.0, keep_ratio: float = 1.0, p: float = 1, handle_device: bool = True) -&gt; tuple[AugmentedDataLoader, AugmentedDataLoader]</code>","text":"<p>See src.polar.train.data.factory.AugmentedDataLoader for the arguments description. Same as     src.polar.train.data.factory.get_augmented_dataloader, but but returns a tuple of train and test dataloaders.</p> <p>Returns:</p> <ul> <li> <code>tuple[AugmentedDataLoader, AugmentedDataLoader]</code>           \u2013            <p>A ModelNet40 dataloader with random motions and degradations.</p> </li> </ul> Source code in <code>src/polar/train/data/factory.py</code> <pre><code>def get_augmented_dataloaders(\n    batch_size: int, num_workers: int,\n    rootdir: str = 'modelnet', classes: Sequence[str] | None = None,\n    exclude_classes: Sequence[str] | None = None, samples_per_class: int | None = None, return_labels: bool = False,\n    num_points: int = 1024, shuffle: bool = False, sigma: float = 0., min_scale: float = 1.,\n    max_angle: float = 180., max_trans: float = 0., keep_ratio: float = 1., p: float = 1, handle_device: bool = True\n) -&gt; tuple[AugmentedDataLoader, AugmentedDataLoader]:\n    \"\"\" See src.polar.train.data.factory.AugmentedDataLoader for the arguments description. Same as\n        [src.polar.train.data.factory.get_augmented_dataloader][], but but returns a tuple of train and test dataloaders.\n\n    Returns:\n        A ModelNet40 dataloader with random motions and degradations. \n    \"\"\"\n    split = 'train'\n    train_loader = get_augmented_dataloader(**locals())\n    split = 'test'\n    locals_ = {k: v for k, v in locals().items() if k != 'train_loader'}\n    test_loader = get_augmented_dataloader(**locals_)\n    return train_loader, test_loader\n</code></pre>"},{"location":"api/data/dataloaders/#src.polar.train.data.factory.get_augmented_dataloader_from_args","title":"<code>get_augmented_dataloader_from_args(args: Namespace) -&gt; AugmentedDataLoader</code>","text":"<p>See src.polar.train.data.factory.AugmentedDataLoader for the arguments description. Same as     src.polar.train.data.factory.get_augmented_dataloader, but accepts an <code>argparse.Namespace</code> object     instead of keyword arguments.</p> <p>Returns:</p> <ul> <li> <code>AugmentedDataLoader</code>           \u2013            <p>A ModelNet40 dataloader with random motions and degradations.</p> </li> </ul> Source code in <code>src/polar/train/data/factory.py</code> <pre><code>def get_augmented_dataloader_from_args(args: Namespace) -&gt; AugmentedDataLoader:\n    \"\"\" See src.polar.train.data.factory.AugmentedDataLoader for the arguments description. Same as\n        [src.polar.train.data.factory.get_augmented_dataloader][], but accepts an `argparse.Namespace` object\n        instead of keyword arguments.\n\n    Returns:\n        A ModelNet40 dataloader with random motions and degradations. \n    \"\"\"\n    dataloader = get_modelnet_dataloader_from_args(args)\n    keys: tuple[str, ...] = ('num_points', 'shuffle', 'sigma', 'min_scale', 'max_angle', 'max_trans', 'keep_ratio',\n                             'source_only', 'p', 'handle_device')\n    params = args_to_param_subset(args, keys)\n    return AugmentedDataLoader(dataloader, **params)\n</code></pre>"},{"location":"api/data/dataloaders/#src.polar.train.data.factory.get_augmented_dataloaders_from_args","title":"<code>get_augmented_dataloaders_from_args(args: Namespace) -&gt; tuple[AugmentedDataLoader, AugmentedDataLoader]</code>","text":"<p>Same as src.polar.train.data.factory.get_augmented_dataloader_from_args, but returns a tuple of train and test     dataloaders.</p> <p>Returns:</p> <ul> <li> <code>tuple[AugmentedDataLoader, AugmentedDataLoader]</code>           \u2013            <p>Train loader, Test loader.</p> </li> </ul> Source code in <code>src/polar/train/data/factory.py</code> <pre><code>def get_augmented_dataloaders_from_args(args: Namespace) -&gt; tuple[AugmentedDataLoader, AugmentedDataLoader]:\n    \"\"\" Same as [src.polar.train.data.factory.get_augmented_dataloader_from_args][], but returns a tuple of train and test\n        dataloaders.\n\n    Returns:\n        Train loader, Test loader.\n    \"\"\"\n    args.split = 'train'\n    train_loader = get_augmented_dataloader_from_args(args)\n    args.split = 'test'\n    test_loader = get_augmented_dataloader_from_args(args)\n    return train_loader, test_loader\n</code></pre>"},{"location":"api/data/functionals/","title":"Functional Point cloud Transformations","text":""},{"location":"api/data/functionals/#common-preprocessing","title":"Common preprocessing","text":""},{"location":"api/data/functionals/#src.polar.train.data.transforms.functionals.center","title":"<code>center(pointclouds: Tensor) -&gt; Tensor</code>","text":"<p>Center each element in a batch of point clouds (substract the mean over the second dim).</p> <p>Parameters:</p> <ul> <li> <code>pointclouds</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds <code>(batch_size, num_points, *)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Batch of centered point clouds.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/functionals.py</code> <pre><code>def center(pointclouds: Tensor) -&gt; Tensor:\n    \"\"\" Center each element in a batch of point clouds (substract the mean over the second dim).\n\n    Args:\n        pointclouds (Tensor): Batch of point clouds `(batch_size, num_points, *)`.\n\n    Returns:\n        Batch of centered point clouds.\n    \"\"\"\n    return pointclouds - pointclouds.mean(dim=1, keepdim=True)\n</code></pre>"},{"location":"api/data/functionals/#src.polar.train.data.transforms.functionals.normalize","title":"<code>normalize(pointclouds: Tensor) -&gt; Tensor</code>","text":"<p>Scale each element in a batch of point clouds so that it lies exactly within the unit sphere.</p> <p>Parameters:</p> <ul> <li> <code>pointclouds</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds <code>(batch_size, num_points, *)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Batch of normalized point clouds.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/functionals.py</code> <pre><code>def normalize(pointclouds: Tensor) -&gt; Tensor:\n    \"\"\" Scale each element in a batch of point clouds so that it lies exactly within the unit sphere.\n\n    Args:\n        pointclouds (Tensor): Batch of point clouds `(batch_size, num_points, *)`.\n\n    Returns:\n        Batch of normalized point clouds.\n    \"\"\"\n    pointclouds_ = center(pointclouds)\n    max_norm = pointclouds_.norm(dim=2).amax(dim=1)\n    return scale(pointclouds_, 1 / max_norm)\n</code></pre>"},{"location":"api/data/functionals/#src.polar.train.data.transforms.functionals.pairwise_max_norm","title":"<code>pairwise_max_norm(pointclouds1: Tensor, pointclouds2: Tensor) -&gt; tuple[Tensor, Tensor]</code>","text":"<p>Scale each pair of elements of the two batches by their maximal norm.</p> <p>Warning</p> <p><code>pointclouds1</code> and <code>pointclouds2</code> MUST have the same length.</p> <p>Parameters:</p> <ul> <li> <code>pointclouds1</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds <code>(batch_size, n, *)</code>.</p> </li> <li> <code>pointclouds2</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds <code>(batch_size, m, *)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[Tensor, Tensor]</code>           \u2013            <p>tuple[Tensor, Tensor]: The two batches of normalized point clouds.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/functionals.py</code> <pre><code>def pairwise_max_norm(pointclouds1: Tensor, pointclouds2: Tensor) -&gt; tuple[Tensor, Tensor]:\n    \"\"\" Scale each pair of elements of the two batches by their maximal norm.\n\n    !!! Warning\n        `pointclouds1` and `pointclouds2` MUST have the same length.\n\n    Args:\n        pointclouds1 (Tensor): Batch of point clouds `(batch_size, n, *)`.\n        pointclouds2 (Tensor): Batch of point clouds `(batch_size, m, *)`.\n\n    Returns:\n        tuple[Tensor, Tensor]: The two batches of normalized point clouds.\n    \"\"\"\n    assert len(pointclouds1) == len(pointclouds2), 'Inputs must be of same length.'\n    norms1 = center(pointclouds1).norm(dim=2).amax(dim=1)  # B\n    norms2 = center(pointclouds2).norm(dim=2).amax(dim=1)  # B\n    max_norms = torch.stack((norms1, norms2)).amax(dim=0)  # (2, B) -&gt; B\n    return scale(pointclouds1, 1 / max_norms), scale(pointclouds2, 1 / max_norms)\n</code></pre>"},{"location":"api/data/functionals/#src.polar.train.data.transforms.functionals.sample","title":"<code>sample(pointclouds: Tensor, indices: Tensor) -&gt; Tensor</code>","text":"<p>Sample the elements of the batch using the provided index tensor.</p> <p>Parameters:</p> <ul> <li> <code>pointclouds</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds <code>(batch_size, num_points, *)</code>.</p> </li> <li> <code>indices</code>               (<code>Tensor</code>)           \u2013            <p>Tensor of indices to keep <code>(batch_size, num_sampled_points)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Batch of sampled point clouds <code>(batch_size, num_sampled_points, *)</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/functionals.py</code> <pre><code>def sample(pointclouds: Tensor, indices: Tensor) -&gt; Tensor:\n    \"\"\" Sample the elements of the batch using the provided index tensor.\n\n    Args:\n        pointclouds (Tensor): Batch of point clouds `(batch_size, num_points, *)`.\n        indices (Tensor): Tensor of indices to keep `(batch_size, num_sampled_points)`.\n\n    Returns:\n        Batch of sampled point clouds `(batch_size, num_sampled_points, *)`.\n    \"\"\"\n    return pointclouds.gather(1, indices.repeat(3, 1, 1).permute(1, 2, 0).to(pointclouds.device))\n</code></pre>"},{"location":"api/data/functionals/#sim3","title":"SIM(3)","text":""},{"location":"api/data/functionals/#src.polar.train.data.transforms.functionals.translate","title":"<code>translate(pointclouds: Tensor, t: Tensor) -&gt; Tensor</code>","text":"<p>Apply a unique translation to each element of the batch of point clouds.</p> <p>Parameters:</p> <ul> <li> <code>pointclouds</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds <code>(batch_size, num_points, *)</code>.</p> </li> <li> <code>t</code>               (<code>Tensor</code>)           \u2013            <p>Batch of translation vectors <code>(batch_size, *)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Batch of translated point clouds <code>(batch_size, num_points, *)</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/functionals.py</code> <pre><code>def translate(pointclouds: Tensor, t: Tensor) -&gt; Tensor:\n    \"\"\" Apply a unique translation to each element of the batch of point clouds.\n\n    Args:\n        pointclouds (Tensor): Batch of point clouds `(batch_size, num_points, *)`.\n        t (Tensor): Batch of translation vectors `(batch_size, *)`.\n\n    Returns:\n        Batch of translated point clouds `(batch_size, num_points, *)`.\n    \"\"\"\n    return pointclouds + t[:, None, :].to(pointclouds.device)\n</code></pre>"},{"location":"api/data/functionals/#src.polar.train.data.transforms.functionals.rotate","title":"<code>rotate(pointclouds: Tensor, R: Tensor) -&gt; Tensor</code>","text":"<p>Apply a unique rotation to each element of the batch of point clouds.</p> <p>Parameters:</p> <ul> <li> <code>pointclouds</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds <code>(batch_size, num_points, 3)</code>.</p> </li> <li> <code>R</code>               (<code>Tensor</code>)           \u2013            <p>Batch of rotation matrices <code>(batch_size, 3, 3)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Batch of rotated point clouds <code>(batch_size, num_points, 3)</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/functionals.py</code> <pre><code>def rotate(pointclouds: Tensor, R: Tensor) -&gt; Tensor:\n    \"\"\" Apply a unique rotation to each element of the batch of point clouds.\n\n    Args:\n        pointclouds (Tensor): Batch of point clouds `(batch_size, num_points, 3)`.\n        R (Tensor): Batch of rotation matrices `(batch_size, 3, 3)`.\n\n    Returns:\n        Batch of rotated point clouds `(batch_size, num_points, 3)`.\n    \"\"\"\n    return pointclouds.bmm(R.mT.to(pointclouds.device))\n</code></pre>"},{"location":"api/data/functionals/#src.polar.train.data.transforms.functionals.apply_rigid_motion","title":"<code>apply_rigid_motion(pointclouds: Tensor, R_or_T: Tensor, t: Tensor | None = None) -&gt; Tensor</code>","text":"<p>Apply a unique rigid motion, i.e. the composition of a rotation and a translation to     each point cloud in the batch.</p> <p>Parameters:</p> <ul> <li> <code>pointclouds</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds <code>(batch_size, num_points, *)</code>.</p> </li> <li> <code>R_or_T</code>               (<code>Tensor</code>)           \u2013            <p>If <code>t</code> is None, this must be a rigid motion matrix <code>(batch_size, 4, 4)</code>.</p> </li> <li> <code>t</code>               (<code>Tensor | None</code>, default:                   <code>None</code> )           \u2013            <p>Batch of translation vectors <code>(batch_size, 3)</code>. Defaults to <code>None</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If <code>t</code> is <code>None</code> and <code>R_or_T</code> is not of shape <code>(batch_size, 4, 4)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code> (              <code>Tensor</code> )          \u2013            <p>Batch of rigidly moved point clouds <code>(batch_size, num_points, 3)</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/functionals.py</code> <pre><code>def apply_rigid_motion(pointclouds: Tensor, R_or_T: Tensor, t: Tensor | None = None) -&gt; Tensor:\n    \"\"\" Apply a unique rigid motion, *i.e.* the composition of a rotation and a translation to\n        each point cloud in the batch.\n\n    Args:\n        pointclouds (Tensor): Batch of point clouds `(batch_size, num_points, *)`.\n        R_or_T (Tensor): If `t` is None, this must be a rigid motion matrix `(batch_size, 4, 4)`.\n        t (Tensor | None, optional): Batch of translation vectors `(batch_size, 3)`. Defaults to `None`.\n\n    Raises:\n        ValueError: If `t` is `None` and `R_or_T` is not of shape `(batch_size, 4, 4)`.\n\n    Returns:\n        Tensor: Batch of rigidly moved point clouds `(batch_size, num_points, 3)`.\n    \"\"\"\n    if t is not None:\n        return translate(rotate(pointclouds, R_or_T), t)\n    if not R_or_T.shape[1:] == (4, 4):\n        raise ValueError('when translation is not given, a batch of (4, 4) motions but be given.')\n    R, t = R_or_T[:, :3, :3], R_or_T[:, :3, 3]\n    return translate(rotate(pointclouds, R), t)\n</code></pre>"},{"location":"api/data/functionals/#src.polar.train.data.transforms.functionals.scale","title":"<code>scale(pointclouds: Tensor, values: Tensor) -&gt; Tensor</code>","text":"<p>Apply a unique scaling factor to each point cloud in the provided batch.</p> <p>Parameters:</p> <ul> <li> <code>pointclouds</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds <code>(batch_size, num_points, *)</code>.</p> </li> <li> <code>values</code>               (<code>Tensor</code>)           \u2013            <p>Batch of scalar scaling values <code>(batch_size,)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Batch of scaled point clouds <code>(batch_size, num_points, *)</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/functionals.py</code> <pre><code>def scale(pointclouds: Tensor, values: Tensor) -&gt; Tensor:\n    \"\"\" Apply a unique scaling factor to each point cloud in the provided batch.\n\n    Args:\n        pointclouds (Tensor): Batch of point clouds `(batch_size, num_points, *)`.\n        values (Tensor): Batch of scalar scaling values `(batch_size,)`.\n\n    Returns:\n        Batch of scaled point clouds `(batch_size, num_points, *)`.\n    \"\"\"\n    return pointclouds * values[:, None, None].to(pointclouds.device)\n</code></pre>"},{"location":"api/data/functionals/#augment","title":"Augment","text":""},{"location":"api/data/functionals/#src.polar.train.data.transforms.functionals.jit","title":"<code>jit(pointclouds: Tensor, sigmas: Tensor) -&gt; Tensor</code>","text":"<p>Add white gaussian noise with variance specified per batch element.</p> <p>Parameters:</p> <ul> <li> <code>pointclouds</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds <code>(batch_size, num_points, *)</code>.</p> </li> <li> <code>sigmas</code>               (<code>Tensor</code>)           \u2013            <p>Noise variance per batch element.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code> (              <code>Tensor</code> )          \u2013            <p>Noisy batch of point clouds X = X + eps, eps ~ N(0, sigma)</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/functionals.py</code> <pre><code>def jit(pointclouds: Tensor, sigmas: Tensor) -&gt; Tensor:\n    \"\"\" Add white gaussian noise with variance specified per batch element.\n\n    Args:\n        pointclouds (Tensor): Batch of point clouds `(batch_size, num_points, *)`.\n        sigmas (Tensor): Noise variance per batch element.\n\n    Returns:\n        Tensor: Noisy batch of point clouds X = X + eps, eps ~ N(0, sigma)\n    \"\"\"\n    gaussian_noise = sigmas[:, None, None].to(pointclouds.device) * torch.randn_like(pointclouds)\n    return pointclouds + gaussian_noise\n</code></pre>"},{"location":"api/data/functionals/#src.polar.train.data.transforms.functionals.plane_cut","title":"<code>plane_cut(pointclouds: Tensor, planes: Tensor, keep_ratio: float, return_mask: bool) -&gt; Tensor | tuple[Tensor, Tensor]</code>","text":"<p>Being given a direction in \\(\\mathcal{S}_3\\), retain points which lie within the half-space oriented in this direction, such that <code>keep_ratio * num_points</code> are retained.</p> <p>Parameters:</p> <ul> <li> <code>pointclouds</code>               (<code>Tensor</code>)           \u2013            <p>Batch of point clouds of shape <code>(batch_size, num_points, 3)</code>.</p> </li> <li> <code>planes</code>               (<code>Tensor</code>)           \u2013            <p>Batch of direction in S3, of shape <code>(batch_size, 3)</code>.</p> </li> <li> <code>keep_ratio</code>               (<code>float</code>)           \u2013            <p>Ratio of points to retain. Outputs will be shaped <code>(batch_size, n, 3)</code>, where <code>n = keep_ratio * num_points</code>.</p> </li> <li> <code>return_mask</code>               (<code>bool</code>)           \u2013            <p>Whether to return the cropping mask alongside the cutted batch.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code> (              <code>Tensor | tuple[Tensor, Tensor]</code> )          \u2013            <p>Batch of cutted pointclouds, of shape <code>(batch_size, keep_ratio * num_points, 3)</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/functionals.py</code> <pre><code>def plane_cut(\n    pointclouds: Tensor, planes: Tensor, keep_ratio: float, return_mask: bool\n) -&gt; Tensor | tuple[Tensor, Tensor]:\n    r\"\"\" Being given a direction in $\\mathcal{S}_3$, retain points which lie within the half-space oriented in\n    this direction, such that `keep_ratio * num_points` are retained.\n\n    Args:\n        pointclouds (Tensor): Batch of point clouds of shape `(batch_size, num_points, 3)`.\n        planes (Tensor): Batch of direction in S3, of shape `(batch_size, 3)`.\n        keep_ratio (float): Ratio of points to retain. Outputs will be shaped `(batch_size, n, 3)`,\n            where `n = keep_ratio * num_points`.\n        return_mask (bool): Whether to return the cropping mask alongside the cutted batch.\n\n    Returns:\n        Tensor: Batch of cutted pointclouds, of shape `(batch_size, keep_ratio * num_points, 3)`.\n    \"\"\"\n    pointclouds = center(pointclouds)\n    distances_from_planes = (pointclouds @ planes[:, :, None].to(pointclouds.device)).squeeze()\n    d_threshold = torch.quantile(distances_from_planes, 1.0 - keep_ratio, dim=1)\n    mask = distances_from_planes &gt; d_threshold[:, None]\n    # Unfortunately, mask does not contain exactly the same number of points per batch element.\n    # I'm forced to do a dirty trick to add some 1 to each line of the mask.\n    # Maybe there's a clever way to do this but I couldn't find it.\n    num_points_to_keep = mask.sum(dim=1).max()\n    zeros = torch.argwhere(~mask)\n    for i in range(len(mask)):\n        current_num_points = mask[i].sum()\n        num_points_to_add = num_points_to_keep - current_num_points\n        mask[zeros[zeros[:, 0] == i][:num_points_to_add].T.unbind()] = True\n    cutted = torch.masked_select(pointclouds, mask[:, :, None]).reshape(len(pointclouds), -1, 3)\n    return (cutted, mask) if return_mask else cutted\n</code></pre>"},{"location":"api/data/sample_data/","title":"Sample dataset","text":""},{"location":"api/data/sample_data/#src.polar.example.utils.load_sample_data","title":"<code>load_sample_data(*keys: str) -&gt; list[Tensor | float] | dict</code>","text":"Accepted keys <p>'all', 'config', 'R_abs_gt', 'template', 'anisotropy', 'cropped_noisy', 'outliers' - If 'all' or len(keys) &gt; 3:     return the whole data dict - If ('anisotropy', 'cropped_noisy', 'outliers') in keys:     return (degraded views, degradation value, R_abs_gt) (+ optionally config, template)</p> <p>Returns:</p> <ul> <li> <code>list[Tensor | float] | dict</code>           \u2013            <p>TODO</p> </li> </ul> Source code in <code>src/polar/example/utils.py</code> <pre><code>def load_sample_data(*keys: str) -&gt; list[Tensor | float] | dict:\n    \"\"\" Accepted keys:\n        'all', 'config', 'R_abs_gt', 'template', 'anisotropy', 'cropped_noisy', 'outliers'\n        - If 'all' or len(keys) &gt; 3:\n            return the whole data dict\n        - If ('anisotropy', 'cropped_noisy', 'outliers') in keys:\n            return (degraded views, degradation value, R_abs_gt) (+ optionally config, template)\n\n    Returns:\n        TODO\n    \"\"\"\n    here = Path(__file__).parent\n    data = torch.load(here / 'data.pt')\n    if 'all' in keys or len(keys) &gt; 3:\n        return data\n    degradations = ('anisotropy', 'cropped_noisy', 'outliers')\n    if len(keys) == 0:\n        i = randint(0, 2)\n        keys = (degradations[i],)\n    msg = \"Only one degradations can be specified. Call `load_sample_data` several times or pass 'all'.\"\n    assert sum([k in degradations for k in keys]) &lt;= 1, msg\n    return_values = list()\n    views = None\n    for k in degradations:\n        if k in keys:\n            views = data['views'][k]\n            value = data['config'][k]\n    if views is not None:\n        return_values.append(views)\n        return_values.append(value)\n        return_values.append(data['R_abs_gt'])\n    for key in ('config', 'template'):\n        if key in keys:\n            return_values.append(data[key])\n    return return_values\n</code></pre>"},{"location":"api/data/transforms/","title":"Transformation Classes","text":"<p>Each functional transform has its <code>class</code> counterpart, except for src.polar.train.data.transforms.functionals.pairwise_max_norm.       In almost all cases, the idea is to have a determinist functional implementation and a random class counterpart.</p>"},{"location":"api/data/transforms/#common-preprocessing","title":"Common preprocessing","text":""},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.Center","title":"<code>Center()</code>","text":"<p>               Bases: <code>Transform</code></p> <p>See src.polar.train.data.transforms.functionals.center.</p> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__()\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.Normalize","title":"<code>Normalize()</code>","text":"<p>               Bases: <code>Transform</code></p> <p>See src.polar.train.data.transforms.functionals.normalize.</p> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__()\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomSample","title":"<code>RandomSample(num_points: int)</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Sample a unique set of points in each batch element. </p> <p>See src.polar.train.data.transforms.functionals.sample.</p> <p>Parameters:</p> <ul> <li> <code>num_points</code>               (<code>int</code>)           \u2013            <p>Number of points to select per point clouds.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def __init__(self, num_points: int) -&gt; None:\n    \"\"\"_summary_\n\n    Args:\n        num_points (int): Number of points to select per point clouds.\n    \"\"\"\n    super().__init__()\n    self.num_points = num_points\n</code></pre>"},{"location":"api/data/transforms/#sim3","title":"SIM(3)","text":""},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomTranslate","title":"<code>RandomTranslate(max_t: float = 0.0, p: float = 1)</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Translate each point cloud in a batch by a random unique value in \\([-\\text{max_t}, \\text{max_t}]\\).       See src.polar.train.data.transforms.functionals.translate.</p> <p>Parameters:</p> <ul> <li> <code>max_t</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Maximal norm of the randomly generated translations. Defaults to <code>0</code>.</p> </li> <li> <code>p</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Probability to apply the random translations. Defaults to <code>1</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def __init__(self, max_t: float = 0., p: float = 1) -&gt; None:\n    \"\"\"_summary_\n\n    Args:\n        max_t (float, optional):\n            Maximal norm of the randomly generated translations. Defaults to `0`.\n        p (float, optional): Probability to apply the random translations. Defaults to `1`.\n    \"\"\"\n    super().__init__(p)\n    self.max_t = max_t\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomRotate","title":"<code>RandomRotate(min_angle: float = 0.0, max_angle: float = 180.0, p: float = 1)</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Rotate each point cloud in a batch by a random unique rotation.        See src.polar.train.data.transforms.functionals.rotate.</p> <p>Warning</p> <p>Angles are in degrees.</p> <p>Parameters:</p> <ul> <li> <code>min_angle</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Minimal relative angle between the identity and the generated rotations. Defaults to <code>0</code>.</p> </li> <li> <code>max_angle</code>               (<code>float</code>, default:                   <code>180.0</code> )           \u2013            <p>Maximal relative angle between the identity and the generated rotations. Defaults to <code>180</code>.</p> </li> <li> <code>p</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Probability to apply the rotations. Defaults to <code>1</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def __init__(self, min_angle: float = 0., max_angle: float = 180., p: float = 1) -&gt; None:\n    \"\"\"_summary_\n\n    !!! Warning\n        Angles are in degrees.\n\n    Args:\n        min_angle (float, optional):\n            Minimal relative angle between the identity and the generated rotations. Defaults to `0`.\n        max_angle (float, optional):\n            Maximal relative angle between the identity and the generated rotations. Defaults to `180`.\n        p (float, optional): Probability to apply the rotations. Defaults to `1`.\n    \"\"\"\n    super().__init__(p)\n    self.min_angle = min_angle * torch.pi / 180\n    self.max_angle = max_angle * torch.pi / 180\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomRotate.random_rotation","title":"<code>random_rotation(n: int, max_angle: float, min_angle: float = 0) -&gt; Tensor</code>  <code>staticmethod</code>","text":"<p>See Rodrigues Rotation Formula,     section Matrix notation. The rotation through an angle \\(\\theta\\) counterclockwise about the axis \\(k = (k_x, k_y, k_z)\\) is given by \\(K =  \\begin{pmatrix} 0 &amp;  -k_z &amp;  k_y \\\\ k_z &amp; 0 &amp; -k_x \\\\ - k_y &amp; k_x &amp; 0\\end{pmatrix}\\) then \\(R = I + \\sin(\\theta)K + (1 - \\cos(\\theta))K\u00b2\\). \\(R\\) is an element of the Lie groupe \\(SO(3)\\) and \\(K\\) is an element of the Lie algebra \\(\\mathfrak{so}(3)\\) generating that group. Note that \\(R = \\exp(\\theta K)\\).</p> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>@staticmethod\ndef random_rotation(n: int, max_angle: float, min_angle: float = 0) -&gt; Tensor:\n    r\"\"\" See [Rodrigues Rotation Formula](https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula),\n        section Matrix notation.\n    The rotation through an angle $\\theta$ counterclockwise about the axis $k = (k_x, k_y, k_z)$ is given by\n    $K = \n    \\begin{pmatrix}\n    0 &amp;  -k_z &amp;  k_y \\\\\n    k_z &amp; 0 &amp; -k_x \\\\\n    - k_y &amp; k_x &amp; 0\\end{pmatrix}$\n    then\n    $R = I + \\sin(\\theta)K + (1 - \\cos(\\theta))K\u00b2$.\n    $R$ is an element of the Lie groupe $SO(3)$ and $K$ is an element of the Lie algebra $\\mathfrak{so}(3)$\n    generating that group. Note that $R = \\exp(\\theta K)$.\n    \"\"\"\n    axis = torch.randn(n, 3)\n    axis /= torch.linalg.vector_norm(axis, dim=1, keepdim=True)\n    angle = min_angle + torch.rand(n).squeeze() * (max_angle - min_angle)\n    zero = torch.zeros(n)\n    K = [[zero, -axis[:, 2], axis[:, 1]], [axis[:, 2], zero, -axis[:, 0]], [-axis[:, 1], axis[:, 0], zero]]\n    K = torch.stack([torch.stack(k) for k in K]).permute(2, 0, 1)\n    sin = torch.sin(angle)[:, None, None]\n    cos = torch.cos(angle)[:, None, None]\n    I = torch.eye(3).expand_as(K)\n    R = I + sin * K + (1 - cos) * K.bmm(K)\n    return R\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomRigidMotion","title":"<code>RandomRigidMotion(max_t: float = 0.0, min_angle: float = 0.0, max_angle: float = 180.0, p: float = 1)</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Rotate &amp; Translate each point cloud in a batch by a random unique rotation. Min/Max angles in degrees.</p> <p>See src.polar.train.data.transforms.functionals.apply_rigid_motion.</p> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def __init__(\n    self, max_t: float = 0., min_angle: float = 0., max_angle: float = 180., p: float = 1\n) -&gt; None:\n    super().__init__(p)\n    self.random_rotate = RandomRotate(min_angle, max_angle)\n    self.random_translate = RandomTranslate(max_t)\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomScale","title":"<code>RandomScale(min_scale: float = 0.0, max_scale: float = 1, p: float = 1)</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Randomly scale a batch of point clouds, with a unique scale factor for each point cloud. </p> <p>See src.polar.train.data.transforms.functionals.scale.</p> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def __init__(self, min_scale: float = 0., max_scale: float = 1, p: float = 1) -&gt; None:\n    super().__init__(p)\n    self.min_scale = min_scale\n    self.max_scale = max_scale\n</code></pre>"},{"location":"api/data/transforms/#augment","title":"Augment","text":""},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomJit","title":"<code>RandomJit(sigma_max: float, p: float = 1)</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Add gaussian noise with unique random standard deviation per point cloud in a batch.     For each batch element, the standard deviation \\(\\sigma\\) is such that     \\(\\sigma \\sim \\mathcal{U}(0, \\text{sigma_max})\\).</p> <p>See src.polar.train.data.transforms.functionals.jit.</p> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def __init__(self, sigma_max: float, p: float = 1) -&gt; None:\n    super().__init__(p)\n    self.sigma_max = sigma_max\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomJit.apply","title":"<code>apply(pointclouds: Tensor, sigmas: Tensor) -&gt; Tensor</code>","text":"<p>Call src.polar.train.data.transforms.functionals.jit on a batch of point clouds, with params obtained by <code>self.get_params(...)</code>.</p> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def apply(self, pointclouds: Tensor, sigmas: Tensor) -&gt; Tensor:\n    \"\"\" Call [src.polar.train.data.transforms.functionals.jit][] on a batch of point clouds, with\n        params obtained by `self.get_params(...)`.\n    \"\"\"\n    return F.jit(pointclouds, sigmas)\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomPlaneCut","title":"<code>RandomPlaneCut(keep_ratio: float = 0.7, p: float = 1)</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Randomly generate a unique plane for each batch element and cut through it, such that a proportion <code>keep_ratio</code> is kept for each point cloud.</p> <p>See src.polar.train.data.transforms.functionals.plane_cut.</p> <p>Parameters:</p> <ul> <li> <code>keep_ratio</code>               (<code>float</code>, default:                   <code>0.7</code> )           \u2013            <p>Proportion of each point cloud to keep. Defaults to 0.7.</p> </li> <li> <code>p</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Probablity to crop a given batch. Defaults to 1.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def __init__(self, keep_ratio: float = 0.7, p: float = 1) -&gt; None:\n    \"\"\"_summary_\n\n    Args:\n        keep_ratio (float, optional): Proportion of each point cloud to keep. Defaults to 0.7.\n        p (float, optional): Probablity to crop a given batch. Defaults to 1.\n    \"\"\"\n    super().__init__(p)\n    self.keep_ratio = keep_ratio\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomPlaneCut.uniform_sphere","title":"<code>uniform_sphere(num: int) -&gt; Tensor</code>  <code>staticmethod</code>","text":"<p>Uniform sampling on a 3-sphere (Source).</p> <p>Parameters:</p> <ul> <li> <code>num</code>               (<code>int</code>)           \u2013            <p>Number of vectors to sample (or <code>None</code> if single). Defaults to <code>None</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code> (              <code>Tensor</code> )          \u2013            <p>Random vector of size <code>(num, 3)</code> with unit norm. If <code>num</code> is <code>None</code>, returned value will have size <code>(3,)</code>.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>@staticmethod\ndef uniform_sphere(num: int) -&gt; Tensor:\n    \"\"\" Uniform sampling on a 3-sphere ([Source](https://gist.github.com/andrewbolster/10274979)).\n\n    Args:\n        num (int, optional): Number of vectors to sample (or `None` if single). Defaults to `None`.\n\n    Returns:\n        Tensor: Random vector of size `(num, 3)` with unit norm. If `num` is `None`, returned value will have\n            size `(3,)`.\n    \"\"\"\n    phi = torch.distributions.Uniform(0, 2 * torch.pi).rsample(torch.Size((num,)))\n    cos_theta = torch.distributions.Uniform(-1.0, 1.0).rsample(torch.Size((num,)))\n    theta = torch.arccos(cos_theta)\n    x = torch.sin(theta) * torch.cos(phi)\n    y = torch.sin(theta) * torch.sin(phi)\n    z = torch.cos(theta)\n    return torch.stack((x, y, z), dim=-1)\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomPlaneCut.get_params","title":"<code>get_params(**data: Tensor) -&gt; dict</code>","text":"<p>Returns a batch of directions sampled in S3, of shape <code>(batch_size, 3)</code> from a     dictionary whose values are batches of point clouds of shape     <code>(batch_size, num_points, spatial_dim)</code>.</p> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>Dictionary with generated planes and keep ratio value.</p> </li> </ul> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def get_params(self, **data: Tensor) -&gt; dict:\n    \"\"\" Returns a batch of directions sampled in S3, of shape `(batch_size, 3)` from a\n        dictionary whose values are batches of point clouds of shape\n        `(batch_size, num_points, spatial_dim)`.\n\n    Returns:\n        Dictionary with generated planes and keep ratio value.\n    \"\"\"\n    batch_size = Transform.get_batch_size(**data)\n    planes = RandomPlaneCut.uniform_sphere(batch_size)\n    return dict(planes=planes, keep_ratio=self.keep_ratio)\n</code></pre>"},{"location":"api/data/transforms/#src.polar.train.data.transforms.transforms.RandomPlaneCut.apply","title":"<code>apply(pointclouds: Tensor, planes: Tensor, keep_ratio: float) -&gt; Tensor</code>","text":"<p>Call src.polar.train.data.transforms.functionals.plane_cut on a batch of point clouds, with params obtained by <code>self.get_params(...)</code>.</p> Source code in <code>src/polar/train/data/transforms/transforms.py</code> <pre><code>def apply(self, pointclouds: Tensor, planes: Tensor, keep_ratio: float) -&gt; Tensor:\n    \"\"\" Call [src.polar.train.data.transforms.functionals.plane_cut][] on a batch of point clouds, with params\n    obtained by `self.get_params(...)`.\n    \"\"\"\n    augmented_pointclouds, mask = F.plane_cut(pointclouds, planes, keep_ratio, return_mask=True)\n    self.last_params['mask'] = mask\n    return augmented_pointclouds\n</code></pre>"},{"location":"api/polar/ae/","title":"PointNet AutoEncoder","text":""},{"location":"api/polar/ae/#src.polar.network.model.PointNetAE","title":"<code>PointNetAE(encoder: PointNet, decoder: ReconstructionHead)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>src/polar/network/model.py</code> <pre><code>def __init__(self, encoder: PointNet, decoder: ReconstructionHead) -&gt; None:\n    super().__init__()\n    self.encoder = encoder\n    self.decoder = decoder\n</code></pre>"},{"location":"api/polar/ae/#src.polar.network.model.PointNetAE.num_params","title":"<code>num_params: dict[str, str]</code>  <code>property</code>","text":"<p>Formatted number of trainable parameters of the encoder and of the decoder.</p> <p>Returns:</p> <ul> <li> <code>dict[str, str]</code>           \u2013            <p>Num Params: Keys: (encoder, decoder). Values: formatted strings of the form '10,000,000'.</p> </li> </ul>"},{"location":"api/polar/ae/#src.polar.network.model.PointNetAE.build","title":"<code>build(in_channels: int = 3, first_stage_widths: tuple[int, ...] = (64, 64), second_stage_widths: tuple[int, ...] = (64, 128, 1024), decoder_widths: tuple[int, ...] = (1024, 1024), num_points: int = 1024, dropout: float = 0.1, out_channels: int = 3) -&gt; PointNetAE</code>  <code>classmethod</code>","text":"<p>Main constructor for the PointNetAE class.</p> <p>Parameters:</p> <ul> <li> <code>in_channels</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Input channels. Defaults to 3.</p> </li> <li> <code>first_stage_widths</code>               (<code>tuple[int, ...]</code>, default:                   <code>(64, 64)</code> )           \u2013            <p>First PointNet MLP layer widths. Defaults to (64, 64).</p> </li> <li> <code>second_stage_widths</code>               (<code>tuple[int, ...]</code>, default:                   <code>(64, 128, 1024)</code> )           \u2013            <p>Second PointNet MLP layer widths. Defaults to (64, 128, 1024).</p> </li> <li> <code>decoder_widths</code>               (<code>tuple[int, ...]</code>, default:                   <code>(1024, 1024)</code> )           \u2013            <p>Decoder MLP layer widths. Defaults to (1024, 1024).</p> </li> <li> <code>num_points</code>               (<code>int</code>, default:                   <code>1024</code> )           \u2013            <p>Decoder number of outputted points. Defaults to 1024.</p> </li> <li> <code>dropout</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>Decoder MLP dropout rate. Defaults to 0.1.</p> </li> <li> <code>out_channels</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Output channels. Defaults to 3.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>PointNetAE</code> (              <code>PointNetAE</code> )          \u2013            <p>PointNet autoencoder.</p> </li> </ul> Source code in <code>src/polar/network/model.py</code> <pre><code>@classmethod\ndef build(\n    cls,\n    in_channels: int = 3,\n    first_stage_widths: tuple[int, ...] = (64, 64),\n    second_stage_widths: tuple[int, ...] = (64, 128, 1024),\n    decoder_widths: tuple[int, ...] = (1024, 1024),\n    num_points: int = 1024,\n    dropout: float = 0.1,\n    out_channels: int = 3,\n) -&gt; PointNetAE:\n    \"\"\" Main constructor for the PointNetAE class.\n\n    Args:\n        in_channels (int, optional): Input channels. Defaults to 3.\n        first_stage_widths (tuple[int, ...], optional):\n            First PointNet MLP layer widths. Defaults to (64, 64).\n        second_stage_widths (tuple[int, ...], optional):\n            Second PointNet MLP layer widths. Defaults to (64, 128, 1024).\n        decoder_widths (tuple[int, ...], optional):\n            Decoder MLP layer widths. Defaults to (1024, 1024).\n        num_points (int, optional):\n            Decoder number of outputted points. Defaults to 1024.\n        dropout (float, optional): Decoder MLP dropout rate. Defaults to 0.1.\n        out_channels (int, optional): Output channels. Defaults to 3.\n\n    Returns:\n        PointNetAE: PointNet autoencoder.\n    \"\"\"\n    latent_dim = second_stage_widths[-1]\n    encoder = PointNet(in_channels, first_stage_widths, second_stage_widths)\n    decoder = ReconstructionHead(latent_dim, decoder_widths, num_points, dropout, out_channels)\n    return cls(encoder, decoder)\n</code></pre>"},{"location":"api/polar/ae/#src.polar.network.model.PointNetAE.from_argparse","title":"<code>from_argparse(args: Namespace) -&gt; PointNetAE</code>  <code>classmethod</code>","text":"<p>Same as src.polar.network.model.PointNetAE.build but taking parameters as a <code>Namespace</code> object.</p> <p>Parameters:</p> <ul> <li> <code>args</code>               (<code>Namespace</code>)           \u2013            <p><code>argparse.Namespace</code> containing the arguments of the build method.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>PointNetAE</code> (              <code>PointNetAE</code> )          \u2013            <p>PointNet autoencoder.</p> </li> </ul> Source code in <code>src/polar/network/model.py</code> <pre><code>@classmethod\ndef from_argparse(cls, args: Namespace) -&gt; PointNetAE:\n    \"\"\" Same as [src.polar.network.model.PointNetAE.build][] but taking parameters as a `Namespace` object.\n\n    Args:\n        args (Namespace): `argparse.Namespace` containing the arguments of the build method.\n\n    Returns:\n        PointNetAE: PointNet autoencoder.\n    \"\"\"\n    ae_params: tuple[str, ...] = ('first_stage_widths', 'second_stage_widths',\n                                  'decoder_widths', 'num_points', 'dropout')\n    ae_params_dict = {k: getattr(args, k) for k in ae_params}\n    ae = cls.build(**ae_params_dict)\n    if 'checkpoint' in args and args.checkpoint is not None:\n        ae.load_state_dict(torch.load(args.checkpoint)['network'])\n    return ae\n</code></pre>"},{"location":"api/polar/ae/#src.polar.network.model.PointNetAE.encode","title":"<code>encode(x: Tensor | Batch) -&gt; Tensor</code>","text":"<p>Encode a batch of point clouds.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor | Batch</code>)           \u2013            <p><code>(batch_size, num_points_i, spatial_dim)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code> (              <code>Tensor</code> )          \u2013            <p><code>(batch_size, latent_dim)</code>.</p> </li> </ul> Source code in <code>src/polar/network/model.py</code> <pre><code>def encode(self, x: Tensor | Batch) -&gt; Tensor:\n    \"\"\" Encode a batch of point clouds.\n\n    Args:\n        x (Tensor | Batch): `(batch_size, num_points_i, spatial_dim)`.\n\n    Returns:\n        Tensor: `(batch_size, latent_dim)`.\n    \"\"\"\n    return self.encoder(x)\n</code></pre>"},{"location":"api/polar/ae/#src.polar.network.model.PointNetAE.decode","title":"<code>decode(z: Tensor) -&gt; Tensor</code>","text":"<p>Decode a batch of latent vectors.</p> <p>Parameters:</p> <ul> <li> <code>z</code>               (<code>Tensor</code>)           \u2013            <p><code>(batch_size, latent_dim)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code> (              <code>Tensor</code> )          \u2013            <p><code>(batch_size, num_points, spatial_dim)</code>.</p> </li> </ul> Source code in <code>src/polar/network/model.py</code> <pre><code>def decode(self, z: Tensor) -&gt; Tensor:\n    \"\"\" Decode a batch of latent vectors.\n\n    Args:\n        z (Tensor): `(batch_size, latent_dim)`.\n\n    Returns:\n        Tensor: `(batch_size, num_points, spatial_dim)`.\n    \"\"\"\n    return self.decoder(z)\n</code></pre>"},{"location":"api/polar/polar/","title":"POLAR","text":""},{"location":"api/polar/polar/#src.polar.polar.POLAR","title":"<code>POLAR(ae: AbstractAE | None = None, batch_size: int = 2048, lr: float = 0.01, patience: int = 100, max_optim_steps: int = 1000, last_joint_fit: bool = True, loss: str = 'latent', fast_approx: bool = True, topk: int = 4, parallel_minima_search: bool = True, R_eps: int = 15, L: float = 50000.0, K: int = 256, estimate_translation: bool = True, estimate_scaling: bool = False, sigmas: float | tuple[float, float, float] | None = None, keep_ratio: float | None = None, outliers_ratio: float | None = None, density_weight: float = 0.01, density_radius: float = 0.1, log_params: bool = False, verbose: bool = True, time: bool = False, pbar: bool = False)</code>","text":"<p>Constructor of the POLAR estimator class.</p> <p>Parameters:</p> <ul> <li> <code>ae</code>               (<code>AbstractAE | None</code>, default:                   <code>None</code> )           \u2013            <p>Accept any autoencoder that implements <code>encode()</code> and <code>decode()</code> methods, and encode a point cloud using a global descriptor (see src.polar.network.model.PointNetAE). If <code>None</code>, load an instance of PointNetAE pretrained on ModelNet40. Defaults to <code>None</code>.</p> </li> <li> <code>batch_size</code>               (<code>int</code>, default:                   <code>2048</code> )           \u2013            <p>Used throughout the whole optimization. Defaults to <code>2048</code>.</p> </li> <li> <code>lr</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>Learning rate. Defaults to <code>1e-2</code>.</p> </li> <li> <code>patience</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>For each joint or multistart fit, stop optimization after <code>max_optim_steps</code> if early stopping wasn't triggered. Defaults to <code>1_000</code>.</p> </li> <li> <code>max_optim_steps</code>               (<code>int</code>, default:                   <code>1000</code> )           \u2013            <p>Each optimization (joint or parallel multistart) will stop after <code>max_optim_steps</code> if early stopping wasn't triggered. Defaults to 1_000.</p> </li> <li> <code>last_joint_fit</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, run a final joint fit after the multistart converged. Defaults to <code>True</code>.</p> </li> <li> <code>loss</code>               (<code>str</code>, default:                   <code>'latent'</code> )           \u2013            <p>'latent' or 'ambient'. Criterion used for both joint and parallel multistart optimizations. For each view \\(\\mathrm{X_i}\\), if 'latent', compute \\(\\lVert \\mathrm{e}(\\rho_i \\mathrm{d}(z)) - \\mathrm{e}(\\mathrm{X_i}) \\rVert\\), else compute \\(d_{\\operatorname{CD}}(\\rho_i \\mathrm{d}(z), \\mathrm{X_i})\\), where \\(d_{\\operatorname{CD}}\\) denotes the Chamfer distance. Defaults to 'latent'.</p> </li> <li> <code>fast_approx</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, do not degrade the estimated template during the local minima search. Defaults to <code>True</code>.</p> </li> <li> <code>topk</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>Number of local minima to try per view. Defaults to <code>4</code>.</p> </li> <li> <code>parallel_minima_search</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, search local minima for each view in parallel. Faster, but may require a lot of VRAM if there are many views and / or <code>topk</code>. Defaults to <code>True</code>.</p> </li> <li> <code>R_eps</code>               (<code>int</code>, default:                   <code>15</code> )           \u2013            <p>Relative angle threshold to detect an escape from a local minima. Defaults to <code>15</code>.</p> </li> <li> <code>L</code>               (<code>float</code>, default:                   <code>50000.0</code> )           \u2013            <p>description. Defaults to 5e4.</p> </li> <li> <code>K</code>               (<code>int</code>, default:                   <code>256</code> )           \u2013            <p>Number of neighbors of a rotation for the local minima search. Defaults to <code>256</code>.</p> </li> <li> <code>estimate_translation</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If False, only estimate 3D rotations. Defaults to True.</p> </li> <li> <code>estimate_scaling</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, estimate a scaling parameter per view, in addition to rotation and translation. Defaults to <code>False</code>.</p> </li> <li> <code>sigmas</code>               (<code>float | tuple[float, float, float] | None</code>, default:                   <code>None</code> )           \u2013            <p>Noise diagonal covariances. If a single float is provided, assume isotropic noise. Else, specify the variance for each axis. Defaults to None.</p> </li> <li> <code>keep_ratio</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Ratio of points that are not occluded in each view, in [0, 1]. Defaults to None.</p> </li> <li> <code>outliers_ratio</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Ratio of points to segment out, in [0, 1]. Defaults to <code>None</code>.</p> </li> <li> <code>density_weight</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>If &gt; 0, will apply a regularization term in the loss. Specify the weight of this ponderation. Defaults to 1e-2.</p> </li> <li> <code>density_radius</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>When <code>density_weight</code> is &gt; 0, a regularization term will be computed. This regularization is the average point density, ie the average number of point in balls of radius <code>density_radius</code>. Defaults to 0.1.</p> </li> <li> <code>log_params</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, logs the evolution of estimated template of motions during the optimization. Slightly slow down the process. Defaults to False.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, print optimization steps. Defaults to True.</p> </li> <li> <code>time</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, log the execution time of each function (mostly for debugging). Defaults to False.</p> </li> <li> <code>pbar</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, display a progress bar for each optimization loop. Defaults to False.</p> </li> </ul> Source code in <code>src/polar/polar.py</code> <pre><code>def __init__(\n    self,\n    # base\n    ae: AbstractAE | None = None,\n    batch_size: int = 2048,\n    # fit\n    lr: float = 1e-2,\n    patience: int = 100,\n    max_optim_steps: int = 1_000,\n    last_joint_fit: bool = True,\n    loss: str = 'latent',\n    # multistart\n    fast_approx: bool = True,\n    topk: int = 4,\n    parallel_minima_search: bool = True,\n    R_eps: int = 15,\n    # SO(3)\n    L: float = 5e4,\n    K: int = 256,\n    # motions\n    estimate_translation: bool = True,\n    estimate_scaling: bool = False,\n    # degradations model\n    sigmas: float | tuple[float, float, float] | None = None,\n    keep_ratio: float | None = None,\n    outliers_ratio: float | None = None,\n    # regularization\n    density_weight: float = 1e-2,\n    density_radius: float = 0.1,\n    # log\n    log_params: bool = False,\n    verbose: bool = True,\n    time: bool = False,\n    # progress bar\n    pbar: bool = False\n) -&gt; None:\n    r\"\"\"_summary_\n\n    Args:\n        ae (AbstractAE | None, optional):\n            Accept any autoencoder that implements `encode()` and `decode()` methods, and encode a point cloud\n            using a global descriptor (see [src.polar.network.model.PointNetAE][]). If `None`, load an instance of\n            PointNetAE pretrained on ModelNet40. Defaults to `None`.\n        batch_size (int, optional): Used throughout the whole optimization. Defaults to `2048`.\n        lr (float, optional): Learning rate. Defaults to `1e-2`.\n        patience (int, optional):\n            For each joint or multistart fit, stop optimization after `max_optim_steps` if early stopping wasn't\n            triggered. Defaults to `1_000`.\n        max_optim_steps (int, optional):\n            Each optimization (joint or parallel multistart) will stop after `max_optim_steps` if early stopping\n            wasn't triggered. Defaults to 1_000.\n        last_joint_fit (bool, optional):\n            If `True`, run a final joint fit after the multistart converged. Defaults to `True`.\n        loss (str, optional): 'latent' or 'ambient'.\n            Criterion used for both joint and parallel multistart optimizations. For each view $\\mathrm{X_i}$, if\n            'latent', compute $\\lVert \\mathrm{e}(\\rho_i \\mathrm{d}(z)) - \\mathrm{e}(\\mathrm{X_i}) \\rVert$, else\n            compute $d_{\\operatorname{CD}}(\\rho_i \\mathrm{d}(z), \\mathrm{X_i})$, where $d_{\\operatorname{CD}}$\n            denotes the Chamfer distance. Defaults to 'latent'.\n        fast_approx (bool, optional):\n            If `True`, do not degrade the estimated template during the local minima search. Defaults to `True`.\n        topk (int, optional): Number of local minima to try per view. Defaults to `4`.\n        parallel_minima_search (bool, optional):\n            If `True`, search local minima for each view in parallel. Faster, but may require a lot of VRAM if\n            there are many views and / or `topk`. Defaults to `True`.\n        R_eps (int, optional): Relative angle threshold to detect an escape from a local minima. Defaults to `15`.\n        L (float, optional): _description_. Defaults to 5e4.\n        K (int, optional): Number of neighbors of a rotation for the local minima search. Defaults to `256`.\n        estimate_translation (bool, optional): If False, only estimate 3D rotations. Defaults to True.\n        estimate_scaling (bool, optional):\n            If `True`, estimate a scaling parameter per view, in addition to rotation and translation.\n            Defaults to `False`.\n        sigmas (float | tuple[float, float, float] | None, optional):\n            Noise diagonal covariances. If a single float is provided, assume isotropic noise. Else, specify\n            the variance for each axis. Defaults to None.\n        keep_ratio (float | None, optional):\n            Ratio of points that are not occluded in each view, in [0, 1]. Defaults to None.\n        outliers_ratio (float | None, optional): Ratio of points to segment out, in [0, 1]. Defaults to `None`.\n        density_weight (float, optional):\n            If &gt; 0, will apply a regularization term in the loss. Specify the weight of this ponderation.\n            Defaults to 1e-2.\n        density_radius (float, optional):\n            When `density_weight` is &gt; 0, a regularization term will be computed. This regularization is the\n            average point density, ie the average number of point in balls of radius `density_radius`.\n            Defaults to 0.1.\n        log_params (bool, optional):\n            If `True`, logs the evolution of estimated template of motions during the optimization. Slightly slow\n            down the process. Defaults to False.\n        verbose (bool, optional): If `True`, print optimization steps. Defaults to True.\n        time (bool, optional):\n            If `True`, log the execution time of each function (mostly for debugging). Defaults to False.\n        pbar (bool, optional): If `True`, display a progress bar for each optimization loop. Defaults to False.\n    \"\"\"\n    self.config = Config(batch_size, lr, patience, max_optim_steps, last_joint_fit, loss,\n                         fast_approx, estimate_translation, estimate_scaling, L, K, R_eps, topk,\n                         parallel_minima_search, sigmas, keep_ratio, outliers_ratio,\n                         density_radius, density_weight, log_params, verbose, pbar, time)\n    # self.register_config()\n    self.batch_size = batch_size\n    self.lr = lr\n    self.patience = patience\n    self.max_optim_steps = max_optim_steps\n    self.last_joint_fit = last_joint_fit\n    self.loss = loss\n    self.fast_approx = fast_approx\n    self.estimate_translation = estimate_translation\n    self.estimate_scaling = estimate_scaling\n    self.L = L\n    self.K = K\n    self.R_eps = R_eps\n    self.topk = topk\n    self.parallel_minima_search = parallel_minima_search\n    self.sigmas = sigmas\n    self.keep_ratio = keep_ratio\n    self.outliers_ratio = outliers_ratio\n    self.density_weight = density_weight\n    self.density_radius = density_radius\n    self.log_params = log_params\n    self.verbose = verbose\n    self.pbar = pbar\n    self.time = time\n    self.base_ae = self.setup_base_ae(ae)\n    self.init_timer()\n</code></pre>"},{"location":"api/polar/polar/#src.polar.polar.POLAR.template","title":"<code>template: Tensor</code>  <code>property</code>","text":"<p>Current estimate of the template: \\(\\mathrm{d}(z) \\in \\mathbb{R}^{K \\times 3}\\).</p> <p>Returns:</p> <ul> <li> <code>Tensor</code> (              <code>Tensor</code> )          \u2013            <p>Template point cloud (K, 3).</p> </li> </ul>"},{"location":"api/polar/polar/#src.polar.polar.POLAR.get_mean_losses","title":"<code>get_mean_losses(multistart: bool = False) -&gt; Tensor</code>","text":"<p>Get the loss evolution during the optimization, averaged over all views.</p> <p>Parameters:</p> <ul> <li> <code>multistart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If False, skip the loss evolution during parallel multistarts, only keeping joint fits evolution. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code> (              <code>Tensor</code> )          \u2013            <p>Average loss evolution.</p> </li> </ul> Source code in <code>src/polar/polar.py</code> <pre><code>def get_mean_losses(self, multistart: bool = False) -&gt; Tensor:\n    \"\"\" Get the loss evolution during the optimization, averaged over all views.\n\n    Args:\n        multistart (bool, optional):\n            If False, skip the loss evolution during parallel multistarts, only keeping joint\n            fits evolution. Defaults to False.\n\n    Returns:\n        Tensor: Average loss evolution.\n    \"\"\"\n    M = self.memories if multistart else filter(lambda m: not m.multistart, self.memories)\n    return torch.hstack([cast(Tensor, m.losses).mean(dim=1) for m in M])\n</code></pre>"},{"location":"api/polar/polar/#src.polar.polar.POLAR.get_matrix","title":"<code>get_matrix(rotation_only: bool = False) -&gt; Tensor</code>","text":"<p>Get the matrix of estimated rigid motions.</p> <p>Parameters:</p> <ul> <li> <code>rotation_only</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, return only the rotation part of the estimated motions. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code> (              <code>Tensor</code> )          \u2013            <p>Tensor of estimated rigid motions: (N, 3, 3) if <code>rotation_only</code> is <code>True</code>, else (N, 4, 4).</p> </li> </ul> Source code in <code>src/polar/polar.py</code> <pre><code>def get_matrix(self, rotation_only: bool = False) -&gt; Tensor:\n    \"\"\" Get the matrix of estimated rigid motions.\n\n    Args:\n        rotation_only (bool, optional):\n            If `True`, return only the rotation part of the estimated motions. Defaults to False.\n\n    Returns:\n        Tensor: Tensor of estimated rigid motions: (N, 3, 3) if `rotation_only` is `True`, else\n            (N, 4, 4).\n    \"\"\"\n    M = self.transforms.get_matrix().detach().cpu()\n    return M[:, :3, :3] if rotation_only else M\n</code></pre>"},{"location":"api/polar/polar/#src.polar.polar.POLAR.fit","title":"<code>fit(X: Views, max_iter: int = 30) -&gt; None</code>","text":"<p>Optimize template and N rigid motions from N views.</p> <p>Note</p> <p><code>Views</code> is a type alias defined as <pre><code>Views: TypeAlias = \"Tensor | Sequence[Tensor]\"\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>Views</code>)           \u2013            <p>Point clouds to register. Tensor (N, K, 3) or list of N Tensors (Ki, 3).</p> </li> <li> <code>max_iter</code>               (<code>int</code>, default:                   <code>30</code> )           \u2013            <p>Maximal number of optimization loop. Defaults to 30.</p> </li> </ul> Source code in <code>src/polar/polar.py</code> <pre><code>def fit(self, X: Views, max_iter: int = 30) -&gt; None:\n    \"\"\" Optimize template and N rigid motions from N views.\n\n    !!! Note\n        `Views` is a type alias defined as\n        ```python\n        Views: TypeAlias = \"Tensor | Sequence[Tensor]\"\n        ```\n\n    Args:\n        X (Views): Point clouds to register. Tensor (N, K, 3) or list of N Tensors (Ki, 3).\n        max_iter (int, optional): Maximal number of optimization loop. Defaults to 30.\n    \"\"\"\n    X = center_max_norm(X)\n    self.init(X)\n    for i in range(max_iter):\n        if self.verbose:\n            print(f'LOOP {i+1}')\n        self.joint_fit()\n        improvements = self.multistart()\n        if len(improvements) == 0:\n            if self.verbose:\n                print('Multistart converged.')\n            break\n        if self.verbose:\n            print(80 * '-')\n    else:\n        print('Max iterations reached. Multistart did not converged.')\n    if self.last_joint_fit:\n        self.joint_fit()\n</code></pre>"},{"location":"api/polar/polar/#src.polar.polar.POLAR.fit_transform","title":"<code>fit_transform(X: Views, max_iter: int = 30) -&gt; Views</code>","text":"<p>Run the fit method, apply the estimated rigid motions to the views and return the registered views.</p> <p>Note</p> <p><code>Views</code> is a type alias defined as <pre><code>Views: TypeAlias = \"Tensor | Sequence[Tensor]\"\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>Views</code>)           \u2013            <p>Point clouds to register. Tensor (N, K, 3) or list of N Tensors (Ki, 3).</p> </li> <li> <code>max_iter</code>               (<code>int</code>, default:                   <code>30</code> )           \u2013            <p>Maximal number of optimization loop. Defaults to 30.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Views</code> (              <code>Views</code> )          \u2013            <p>list of N Tensors (Ki, 3) representing registered views.</p> </li> </ul> Source code in <code>src/polar/polar.py</code> <pre><code>def fit_transform(self, X: Views, max_iter: int = 30) -&gt; Views:\n    \"\"\" Run the fit method, apply the estimated rigid motions to the views and return the\n    registered views.\n\n    !!! Note\n        `Views` is a type alias defined as\n        ```python\n        Views: TypeAlias = \"Tensor | Sequence[Tensor]\"\n        ```\n\n    Args:\n        X (Views): Point clouds to register. Tensor (N, K, 3) or list of N Tensors (Ki, 3).\n        max_iter (int, optional): Maximal number of optimization loop. Defaults to 30.\n\n    Returns:\n        Views: list of N Tensors (Ki, 3) representing registered views.\n    \"\"\"\n    self.fit(X, max_iter)\n    with torch.no_grad():\n        return self.registrate()\n</code></pre>"},{"location":"api/polar/so3/","title":"SO(3) utilities","text":""},{"location":"api/polar/so3/#src.polar.so3.so3_relative_angle","title":"<code>so3_relative_angle(R1: Tensor, R2: Tensor) -&gt; Tensor</code>","text":"<p>Geodesic distance in the manifold of rotations SO(3): \\(\\operatorname{arccos}\\left(\\frac{\\mathrm{tr}(R_1 R_2^\\top) - 1}{2}\\right)\\)</p> <p>Parameters:</p> <ul> <li> <code>R1</code>               (<code>Tensor</code>)           \u2013            <p>Batch of rotation matrices \\((B, 3, 3)\\).</p> </li> <li> <code>R2</code>               (<code>Tensor</code>)           \u2013            <p>Batch of rotation matrices \\((B, 3, 3)\\).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Distances</code> (              <code>Tensor</code> )          \u2013            <p>Batch of distances \\((B,)\\) in \\([0, \\pi]\\).</p> </li> </ul> Source code in <code>src/polar/so3.py</code> <pre><code>def so3_relative_angle(R1: Tensor, R2: Tensor) -&gt; Tensor:\n    r\"\"\" Geodesic distance in the manifold of rotations SO(3):\n    $\\operatorname{arccos}\\left(\\frac{\\mathrm{tr}(R_1 R_2^\\top) - 1}{2}\\right)$\n\n    Args:\n        R1 (Tensor): Batch of rotation matrices $(B, 3, 3)$.\n        R2 (Tensor): Batch of rotation matrices $(B, 3, 3)$.\n\n    Returns:\n        Distances: Batch of distances $(B,)$ in $[0, \\pi]$.\n    \"\"\"\n    cos_theta = (torch.einsum('bij,bij-&gt;b', R1, R2) - 1) / 2\n    cos_theta = torch.clamp(cos_theta, -1, 1)\n    return torch.acos(cos_theta) * 180 / torch.pi\n</code></pre>"},{"location":"api/polar/so3/#src.polar.so3.super_fibonacci_spirals","title":"<code>super_fibonacci_spirals(n: int | float, double: bool = False) -&gt; Tensor</code>","text":"<p>Generate \\(n\\) uniformly spaced rotations. Alexa M., Super-Fibonacci Spirals: Fast, Low-Discrepancy Sampling of SO3, CVPR 2022.</p> <p>Parameters:</p> <ul> <li> <code>n</code>               (<code>int | float</code>)           \u2013            <p>Number of samples to generate.</p> </li> <li> <code>double</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, generated samples are of type <code>double</code>. Defaults to <code>False</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Rotations</code> (              <code>Tensor</code> )          \u2013            <p>Batch of generated rotations \\((n, 3, 3)\\).</p> </li> </ul> Source code in <code>src/polar/so3.py</code> <pre><code>def super_fibonacci_spirals(n: int | float, double: bool = False) -&gt; Tensor:\n    \"\"\" Generate $n$ uniformly spaced rotations.&lt;br&gt;\n    [Alexa M., Super-Fibonacci Spirals: Fast, Low-Discrepancy Sampling of SO3, CVPR 2022.](https://openaccess.thecvf.com/content/CVPR2022/papers/Alexa_Super-Fibonacci_Spirals_Fast_Low-Discrepancy_Sampling_of_SO3_CVPR_2022_paper.pdf)\n\n    Args:\n        n (int | float): Number of samples to generate.\n        double (bool, optional):\n            If `True`, generated samples are of type `double`. Defaults to `False`.\n\n    Returns:\n        Rotations: Batch of generated rotations $(n, 3, 3)$.\n    \"\"\"\n    n = int(n)\n    phi = np.sqrt(2.0)\n    psi = 1.533751168755204288118041\n    Q = np.empty(shape=(n, 4), dtype=np.float64 if double else np.float32)\n    i = np.arange(n)\n    s = i + 0.5\n    r = np.sqrt(s / n)\n    R = np.sqrt(1.0 - s / n)\n    alpha = 2.0 * np.pi * s / phi\n    beta = 2.0 * np.pi * s / psi\n    Q[i, 0] = r * np.sin(alpha)\n    Q[i, 1] = r * np.cos(alpha)\n    Q[i, 2] = R * np.sin(beta)\n    Q[i, 3] = R * np.cos(beta)\n    matrices = T.quaternion_to_matrix(torch.tensor(Q))\n    angles = T.matrix_to_euler_angles(matrices, 'ZXZ')\n    return angles\n</code></pre>"},{"location":"api/polar/so3/#src.polar.so3.get_so3_knn_graph","title":"<code>get_so3_knn_graph(L: int | float, K: int, verbose: bool = False, output_dir: str = '.cache/') -&gt; Graph</code>","text":"<p>Get a k nearest neighbors graph over rotations. Load it from disk if it exists, create it otherwise.</p> <p>Warning</p> <p>This function will search for existing graphs in <code>output_dir.</code> If a new graph must be created, it may takes quite a long time, depending on values of <code>L</code> and <code>K</code>.</p> <p>Parameters:</p> <ul> <li> <code>L</code>               (<code>int | float</code>)           \u2013            <p>Number of nodes (rotations) in the graph.</p> </li> <li> <code>K</code>               (<code>int</code>)           \u2013            <p>Number of neighbors.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, display infos about the graph retrieving. Defaults to <code>False</code>.</p> </li> <li> <code>output_dir</code>               (<code>str</code>, default:                   <code>'.cache/'</code> )           \u2013            <p>Where to look for or store the graph. Defaults to <code>\".cache/\"</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Graph</code> (              <code>Graph</code> )          \u2013            <p>\\(SO(3)\\) knn graph. Keys: <code>indices</code>, <code>relative_angles</code></p> </li> </ul> Source code in <code>src/polar/so3.py</code> <pre><code>def get_so3_knn_graph(L: int | float, K: int, verbose: bool = False, output_dir: str = \".cache/\", ) -&gt; Graph:\n    \"\"\" Get a k nearest neighbors graph over rotations. Load it from disk if it exists, create it otherwise.\n\n    !!! Warning\n        This function will search for existing graphs in `output_dir.` If a new graph must be created,\n        it may takes quite a long time, depending on values of `L` and `K`.\n\n\n    Args:\n        L (int | float): Number of nodes (rotations) in the graph.\n        K (int): Number of neighbors.\n        verbose (bool, optional): If `True`, display infos about the graph retrieving. Defaults to `False`.\n        output_dir (str, optional): Where to look for or store the graph. Defaults to `\".cache/\"`.\n\n    Returns:\n        Graph: $SO(3)$ knn graph. Keys: `indices`, `relative_angles`\n    \"\"\"\n    L = int(L)\n    here = Path(__file__).resolve().parent\n    output_path = here / output_dir\n    filename = f\"so3_knn_lookup_table_indices_L={L}_K={K}.pt\"\n    if not (output_path / filename).exists() and verbose:\n        print((\n            \"Cached SO(3) Lookup Table not found. \"\n            \"It will be created on the fly and saved for later use. \"\n            \"This will occur extra runtime.\"\n        ))\n        make_and_save_so3_knn_lookup_table(L, K, output_dir)\n    elif verbose:\n        print(\"    - Using cached SO(3) knn-graph.\")\n    path = output_path / f\"so3_knn_lookup_table_indices_L={L}_K={K}.pt\"\n    indices = torch.load(path)\n    path = output_path / f\"so3_knn_lookup_table_angles_L={L}_K={K}.pt\"\n    angles = torch.load(path)\n    knn_graph = {i: {'indices': indices[i],\n                     'relative_angles': angles[i]} for i in range(len(indices))}\n    return cast(Graph, knn_graph)\n</code></pre>"},{"location":"api/polar/so3/#src.polar.so3.single_view_find_so3_local_minima_from_knn_graph","title":"<code>single_view_find_so3_local_minima_from_knn_graph(so3_knn_graph: Graph, values: Tensor) -&gt; Tensor</code>","text":"<p>Use a knn SO(3) graph (from src.polar.so3.get_so3_knn_graph) of \\(L\\) rotations to find local minima in  one single set of \\(L\\) <code>values</code> associated to these rotations.</p> <p>Parameters:</p> <ul> <li> <code>so3_knn_graph</code>               (<code>Graph</code>)           \u2013            <p>Graph where nodes are rotations. Each node is connected to its k nearest neighbors (according to the src.polar.so3.so3_relative_angle distance.)</p> </li> <li> <code>values</code>               (<code>Tensor</code>)           \u2013            <p>Values in which to find local minima \\((L,)\\).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>LocalMinima</code> (              <code>Tensor</code> )          \u2013            <p>Tensor of local minima indices in range \\([0, L]\\).</p> </li> </ul> Source code in <code>src/polar/so3.py</code> <pre><code>def single_view_find_so3_local_minima_from_knn_graph(so3_knn_graph: Graph, values: Tensor) -&gt; Tensor:\n    \"\"\" Use a knn SO(3) graph (from [src.polar.so3.get_so3_knn_graph][]) of $L$ rotations to find local minima in \n    one single set of $L$ `values` associated to these rotations.\n\n    Args:\n        so3_knn_graph (Graph): Graph where nodes are rotations. Each node is connected to its k nearest neighbors\n            (according to the [src.polar.so3.so3_relative_angle][] distance.)\n        values (Tensor): Values in which to find local minima $(L,)$.\n\n    Returns:\n        LocalMinima: Tensor of local minima indices in range $[0, L]$.\n    \"\"\"\n    neighbors = torch.stack([n['indices'] for n in so3_knn_graph.values()])  # type: ignore\n    local_minima_indices = (values[:, None] &lt;= values[neighbors]).all(dim=1).argwhere().squeeze()\n    return local_minima_indices[values[local_minima_indices].argsort()]\n</code></pre>"},{"location":"api/polar/so3/#src.polar.so3.find_so3_local_minima_from_knn_graph","title":"<code>find_so3_local_minima_from_knn_graph(so3_knn_graph: Graph, values: Tensor, parallel: bool) -&gt; list[Tensor]</code>","text":"<p>Use a knn SO(3) graph (from src.polar.so3.get_so3_knn_graph) of \\(L\\) rotations to find local minima in  \\(N\\) sets of \\(L\\) <code>values</code> associated to these rotations.</p> <p>Parameters:</p> <ul> <li> <code>so3_knn_graph</code>               (<code>Graph</code>)           \u2013            <p>Graph where nodes are rotations. Each node is connected to its k nearest neighbors (according to the src.polar.so3.so3_relative_angle distance.)</p> </li> <li> <code>values</code>               (<code>Tensor</code>)           \u2013            <p>Values in which to find local minima \\((N, L)\\).</p> </li> <li> <code>parallel</code>               (<code>bool</code>)           \u2013            <p>If <code>True</code>, local minima in each of the <code>N</code> sets of <code>L</code> distances are searched in parallel. Otherwise, run \\(N\\) sequential searches.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>LocalMinima</code> (              <code>list[Tensor]</code> )          \u2013            <p>List of \\(N\\) local minima indices in range \\([0, L]\\).</p> </li> </ul> Source code in <code>src/polar/so3.py</code> <pre><code>def find_so3_local_minima_from_knn_graph(so3_knn_graph: Graph, values: Tensor, parallel: bool) -&gt; list[Tensor]:\n    \"\"\" Use a knn SO(3) graph (from [src.polar.so3.get_so3_knn_graph][]) of $L$ rotations to find local minima in \n    $N$ sets of $L$ `values` associated to these rotations.\n\n    Args:\n        so3_knn_graph (Graph): Graph where nodes are rotations. Each node is connected to its k nearest neighbors\n            (according to the [src.polar.so3.so3_relative_angle][] distance.)\n        values (Tensor): Values in which to find local minima $(N, L)$.\n        parallel (bool): If `True`, local minima in each of the `N` sets of `L` distances are searched in parallel.\n            Otherwise, run $N$ sequential searches.\n\n    Returns:\n        LocalMinima: List of $N$ local minima indices in range $[0, L]$.  \n    \"\"\"\n    if parallel:\n        return parallel_find_so3_local_minima_from_knn_graph(so3_knn_graph, values)\n    return [single_view_find_so3_local_minima_from_knn_graph(so3_knn_graph, v) for v in values]\n</code></pre>"},{"location":"examples/examples/","title":"Introduction","text":"<pre><code>from PIL import Image\nfrom matplotlib import pyplot as plt\nfrom utils import working_directory, interactive_plot, get_errors_index\nwith working_directory('..'):\n    from polar import load_sample_data, POLAR\n</code></pre> <p><code>kaleido</code> is only required to save Plotly figures as jpeg image, so that they can be displayed in the web documentation.     It is not required when running this notebook.</p> <pre><code>%pip install -U kaleido\n</code></pre> <pre>\n<code>Requirement already satisfied: kaleido in /data/mambaforge/envs/geom/lib/python3.8/site-packages (0.2.1)\n</code>\n</pre> <pre><code>views, degradations, R_abs_gt = load_sample_data('outliers')\n</code></pre> <pre><code>model = POLAR(**degradations)\n</code></pre> <pre><code>model.fit(views.cuda())\n</code></pre> <pre>\n<code>:: Initializing model ...\n    - Using device: cuda.\nCached SO(3) Lookup Table not found. It will be created on the fly and saved for later use. This will occur extra runtime.\n    - Running coarse exhaustive search ...\nLOOP 1\n:: Running 100 parallel joint optimizations ...\n:: Computing restart angles ...\n:: Running 400 parallel multistart optimizations ...\nMultistart improved 16 objects:\ntensor([12, 19, 21, 27, 29, 32, 35, 42, 46, 56, 70, 75, 76, 86, 94, 95])\n--------------------------------------------------------------------------------\nLOOP 2\n:: Running 100 parallel joint optimizations ...\n:: Computing restart angles ...\n:: Running 400 parallel multistart optimizations ...\nMultistart improved 1 objects:\ntensor([48])\n--------------------------------------------------------------------------------\nLOOP 3\n:: Running 100 parallel joint optimizations ...\n:: Computing restart angles ...\n:: Running 400 parallel multistart optimizations ...\nMultistart improved 1 objects:\ntensor([48])\nMultistart improved same objects twice in a row.\nReducing lr to 0.001.\n--------------------------------------------------------------------------------\nLOOP 4\n:: Running 100 parallel joint optimizations ...\n:: Computing restart angles ...\n:: Running 400 parallel multistart optimizations ...\nMultistart improved 1 objects:\ntensor([37])\n--------------------------------------------------------------------------------\nLOOP 5\n:: Running 100 parallel joint optimizations ...\n:: Computing restart angles ...\n:: Running 400 parallel multistart optimizations ...\nMultistart converged.\n:: Running 100 parallel joint optimizations ...\n</code>\n</pre> <pre><code>get_errors_index(model.get_matrix(rotation_only=True), R_abs_gt)\n</code></pre> <pre>\n<code>tensor([89])</code>\n</pre> <pre><code>loss = model.get_mean_losses(multistart=True)\n</code></pre> <pre><code>plt.plot(loss); plt.show()\n</code></pre> <p>This is just to display the Plotly figure as an image in the web documentation.        If you are running this notebook, just call <code>interactive_plot(model.template.detach())</code></p> <pre><code>fig = interactive_plot(model.template.detach(), return_fig=True)\n</code></pre> <pre><code>fig.show()\n</code></pre> <pre><code>fig.write_image(\"template.jpeg\")\nImage.open('./template.jpeg')\n</code></pre> <pre><code>\n</code></pre>"}]}